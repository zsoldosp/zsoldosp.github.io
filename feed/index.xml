<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Do. Reflect. Learn. Repeat!</title>
    <link>http://blog.zsoldosp.eu</link>
    <description>Excercises in public learning</description>
    <pubDate>Sun, 19 Jan 2014 10:29:03 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>Green Build Surprises</title>
      <link>http://blog.zsoldosp.eu/2014/01/19/green-build-surprises/</link>
      <pubDate>Sun, 19 Jan 2014 11:30:00 CET</pubDate>
      <category><![CDATA[monitoring]]></category>
      <category><![CDATA[continuous integration]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">Fp298W8YFUYXUTLCJhSRMzFmERU=</guid>
      <description>Green Build Surprises</description>
      <content:encoded><![CDATA[<p>Recently while working on our build process, I ran into an unexpected
surprise - the build server reported no error (i.e.: it was displaying a
green status, since all tests were passing), yet there was a major issue
- not all of our tests were run!</p>
<p>Given that the situation was caused by working on the build itself, the
issue was discovered in time (<strike>though somewhat accidentally</strike>
during <a href="https://en.wikipedia.org/wiki/Exploratory_testing">exploratory testing</a>). However, this was a
nice reminder of the problem with the "unknown unknowns" - now that we
know of this issue, of course we have configured alerting for the case
when the current build ran less tests than the build before. But I
wonder how many times we may have released on a green build with
regression bugs...</p>
<p>Asking some others and looking back on my past experiences, this topic
hasn't come up, so while I hope it is obvious and not news for you, dear
reader, I blog it just in case I wasn't the last to get the memo...</p>
<p>And it turns out that every now and then we do mess up and commit code
that makes some tests invisible to the test runner... So it wasn't just
a one-off thing!</p>]]></content:encoded>
    </item>
    <item>
      <title>Going Beyond Regression - What Other Benefits could End-to-End Testing Provide?</title>
      <link>http://blog.zsoldosp.eu/2013/10/28/going-beyond-regression-what-other-benefits-could-end-to-end-testing-provide/</link>
      <pubDate>Mon, 28 Oct 2013 08:05:00 CET</pubDate>
      <category><![CDATA[untested ideas]]></category>
      <category><![CDATA[code]]></category>
      <category><![CDATA[business analysis]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[end-to-end]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">1ojU7m2klQVoaVtPAyBIp7nHdds=</guid>
      <description>Going Beyond Regression - What Other Benefits could End-to-End Testing Provide?</description>
      <content:encoded><![CDATA[<p>In last week's post, I gave a few examples about when <a href="/2013/10/23/a-new-look-at-end-to-end-testing-polymorphic-and-fast/">Polymorphic
End-to-End Testing</a> testing makes sense. In this post, I would
like to take a step back and list a few additional benefits that could
be derived from end to end testing in general, regardless of the fashion
they were written in.</p>
<p><em>Note: some of these points can also apply to non-end-to-end tests too,
that were written in a black box style with proper test abstractions. 
While it could be argued that then the system is that one component, I
would rather just focus on the benefits we can derive on top of the 
regression / specification of the system.</em></p>
<p><em>Disclaimer:</em> note this post has been filed under <a href="/category/untested-ideas/">untested ideas</a>
 - they sound good, but I haven't gotten around to implementing all of
them.</p>
<h2 id="big-refactorings-and-rewrites">Big Refactorings and Rewrites</h2>
<p>Change is inevitable, and they often violate previous assumptions. 
Sometimes whole components (or systems) have to be rewritten. Having a 
set of tests that operate on a much higher abstraction level (e.g.: HTTP
GET/POST requests) can provide the required safety net to avoid 
regressions and making sure all relevant scenarios are addressed.</p>
<p>Some changes where this Page (Application) Object abstraction has helped
us:</p>
<ul>
<li>when converting a single page checkout process to a multi-step 
    wizard style checkout</li>
<li>when the article numbers used in our system changed</li>
<li>when we had to synchronize data into a new system - we could just 
    expand our assertions in the end-to-end tests to make sure that 
    every known scenario is written correctly into the new system</li>
</ul>
<p><a href="http://blog.8thlight.com/uncle-bob/2013/09/23/Test-first.html">It's easy to reconstruct a system from its tests, but much harder to do
it the other way around</a>. It has been
great to only adjust a few driver API methods and get the same amount of
functional coverage as before, without having to rewrite the test suite.</p>
<h2 id="forces-the-team-to-think-about-the-user-interface-and-experience">Forces the team to think about the user interface (and experience)</h2>
<p>While it is not required, it often made us reduce the complexity in 
the UI - when we find that a certain step is being exercised by a 
method with a single parameter from the tests, yet that method then 
derives a bunch of additional parameters to POST against the page, it
suggests one of two things: </p>
<ol>
<li>we are missing some test cases for these extra parameters</li>
<li>maybe we don't need these parameters to be provided by the end user,
    but we could derive them in the application too.</li>
</ol>
<p>Often the helper methods created can expose the need for additional 
support interfaces that won't probably come up during the specifications
phase, only after go-live.<br />
</p>
<p>Last, but not least, end-to-end gives us tests for the UI, yet the tests
remain maintainable - usually a single test API method is all that needs
to be fixed after template changes (and designers are even harder to get
to write tests than developers :)). <a href="http://ayende.com/blog/160929/on-failing-tests">Don't be afraid of many test 
failures!</a></p>
<h2 id="correlate-tests-with-other-business-metrics">Correlate tests with other business metrics</h2>
<p>While I recall people suggesting we run applications with a <a href="https://en.wikipedia.org/wiki/Code_coverage">coverage 
profiler attached</a>, the performance penalty is usually 
prohibiting.</p>
<p>However, I haven't yet seen a web application without a ton of external
metrics related to the urls in the app. If our tests are written against
urls too, after some data munging (primary keys and actual form values
surely won't match test values exactly, but translating them to <code>GET to 
view 1</code>, <code>POST to view 2</code>) we can correlate our tests with these 
metrics. </p>
<p>Some such metrics:</p>
<ul>
<li>application (webserver) access logs</li>
<li>Google Analytics or equivalent</li>
<li>...</li>
</ul>
<p>What can we learn from these correlations/comparisons?</p>
<ul>
<li>are we concentrating our tests in the least visited areas?</li>
<li>are we testing what our users are doing? Sure, it's nice that in our
    tests people sequentially finish their checkout, without wondering
    off the known path, but is this how they behave in production?</li>
</ul>
<h2 id="testcase-similarity-analysis">TestCase similarity analysis</h2>
<p>Some test scenarios will come up in multiple aspects of the system. 
Placing an order will trigger a bunch of actions in other modules - 
fulfillment, customer profile updates, marketing classification, invoice
rendering, notification emails, etc.</p>
<p>Sometimes these features are added with big time gaps in between, maybe
even the team members have changed over time. The ability to compare 
the requests the different TestCases make, and say that these two 
(three, four, etc.) TestCases seem to execute the same kind of requests
up to a point as the TestCase being added, but they also have the 
following extra paths they all execute, but the new TestCase doesn't...
Causing the developer to realize - of course, there are special rules
for orders from educational institutions!</p>
<h2 id="reducing-the-gap-between-end-user-error-reports-and-tests">Reducing the gap between end user error reports and tests</h2>
<p>Probably this is the least unexpected idea in the list, but worth 
stating nonetheless.</p>
<h2 id="in-place-help-for-trusted-users">In place help (for trusted users)</h2>
<p>Sure, this might require careful considerations, but giving the users 
the ability to browse the test cases/methods that matches their workflow
up to the current page, in a searchable fashion (if I place an order 
like this now, when will the X email be sent) could greatly reduce 
support work for the developer team. <em>Note: the purpose of this is not 
to isolate the developers from the users!!!</em></p>
<h2 id="always-up-to-date-screenshots-and-videos">Always up-to-date screenshots and videos</h2>
<p>Those manuals that have screenshots from many releases ago... Adding (or
marking) some test cases to be linked against documentation sections, and
having the tests actually take screenshots about them or record them as 
video sounds like a pretty useful idea for me. One could go further, 
such as highlighting the values/input fields where the test sends 
input, and the parts of the page that are asserted against...</p>
<p>And if the support team has access to the same API, they could even 
create these screenshots/videos for the customer as they are answering
their question (Here, take a look at this video, this is how the thing
you asked for is done).</p>
<hr />
<p>There must be many more ideas out there - let me know about them, and 
I'm happy to add them to this list (or link to wherever you published
it)!</p>]]></content:encoded>
    </item>
    <item>
      <title>A New Look At End-to-End Testing - Polymorphic and Fast</title>
      <link>http://blog.zsoldosp.eu/2013/10/23/a-new-look-at-end-to-end-testing-polymorphic-and-fast/</link>
      <pubDate>Wed, 23 Oct 2013 19:28:00 CEST</pubDate>
      <category><![CDATA[untested ideas]]></category>
      <category><![CDATA[end-to-end]]></category>
      <category><![CDATA[code]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">ity9bCalQkCuoSztWSPkSrQ8XGs=</guid>
      <description>A New Look At End-to-End Testing - Polymorphic and Fast</description>
      <content:encoded><![CDATA[<p>At the end of this post, there is a list of reasons why to work with 
end-to-end tests, but first please consider the post's idea on its own.
After that, I'm glad to have discussions about alternative/better 
solutions to the described (or omitted) contexts.</p>
<p>Please, read it first ;)</p>
<h1 id="terms-used">Terms used</h1>
<p>The below points are not intended to be full blown definitions, but
rather pointers.</p>
<ul>
<li>End-to-End testing - as <a href="http://gojko.net/2010/03/31/tdd-with-complex-infrastructures/">Nat Pryce has said in one of his 
    presentations</a>, the ends are always farther apart than one 
    thinks they are. The purpose is to execute the tests through as much
    of the application stack as possible - from the front end at least
    till the storage mechanism.</li>
<li>Polymorphism - I use it here mostly in the way demonstrated by the 
    <a href="https://en.wikipedia.org/wiki/Liskov_Substitution_Principle">Liskov Substitution Principle</a> - code written against an abstraction
    should be unaffected regardless of the concrete implementation of 
    that abstraction is given to it.</li>
</ul>
<h1 id="polymorphic-tests-we-are-already-doing-it">Polymorphic tests - we are already doing it</h1>
<p>Some of us already run the same tests on top of different code - we can
have multiple build platforms (x86 and x64, Windows and Linux, Python 2 
and 3, etc.), multiple configurations (SQLite and PostgreSQL), as well
as multiple versions of our dependent libraries (stable, latest release, 
and latest). What's common though among these scenarios is that the 
polymorphism happens largely <em>outside</em> of our codebase, and we don't 
have to think much about it when writing tests. </p>
<p>An example of executing multiple drivers <em>inside</em> our code is the use of 
Selenium tests - the same tests are run against Chrome, Firefox, etc. 
While each of the drivers is testing on the same level (Web UI), the 
actual browser drivers have different implementations, exposed via a 
common abstraction level - DOM selectors and event invocations.</p>
<p>Of course, most test code uses some level of abstraction to separate
the test logic from the actual page implementations.</p>
<h1 id="abstractions-page-objects">Abstractions - Page objects</h1>
<p>The <a href="http://martinfowler.com/bliki/PageObject.html">Page Object</a> pattern is used to help creating maintainable tests.
Instead of writing tests coupled to the implementations (go to this 
concrete url, wait <code>N</code> seconds for it to load, find and select the form
elements for username and password, etc.), these implementation details 
are hidden behind well named methods (e.g.: <code>open_login_form</code>, 
<code>login_with_credentials</code>, etc.), and thus are domain (client) friendly
and readable. And Page Objects can be composed together to build 
Application Objects.</p>
<p>Similar abstraction is used by the various Acceptance Testing tools,
such as FitNesse, Cucumber, and the other Gherkin tools - the spec texts
contain terms and values important for the business domain, and there
is separate code translating the spec's values and terms to call into 
the application and transforming its state into a format
expected by the tool.</p>
<h1 id="stripped-down-tests-only-the-script">Stripped down tests - only the script</h1>
<p>As seen above, the AT tools separate application logic from the test 
scenario's description.</p>
<p>Assertions have also been separated from test cases - either by developer 
choice, choosing to use a separate Assertions library like Hamcrest, 
instead of the unit testing library's own <code>assertFoo</code> methods), or
explicitly (<a href="http://visionmedia.github.io/mocha/#assertions">Mocha ships without an assertions library</a>).</p>
<p>Thus tests can really be focused just on the scenario being tested.</p>
<h1 id="fast-tests">Fast tests</h1>
<p>The single biggest disadvantage of <a href="http://www.confreaks.com/videos/641-gogaruco2011-fast-rails-tests">end to end tests is their speed</a>. They are slow. And the more of them there are, the slower they are.</p>
<p>This is one reason why the <a href="http://martinfowler.com/bliki/TestPyramid.html">Test Pyramid</a> recommends not having 
too many of them. Many architectural approaches (<a href="http://alistair.cockburn.us/Hexagonal+architecture">hexagonal</a>, DDD, etc.) 
suggest keeping a lightweight core application, and to attach the 
persistence and UI layers to it at its boundaries, leaving these ports 
and adapters lightweight too. Most of the testing then happens against
the core, dependency independent code, making the tests fast. </p>
<h1 id="fast-end-to-end-tests">Fast end to end tests</h1>
<p>Drumroll... we'll do a bit of cheating, of course. </p>
<p>Not all the tests have to run every single time. Performance tests are
usually not done when TDDing - that kicks in either later in 
the deployment pipeline, or runs daily. Teams organize their tests into
fast, smoke, and slow suites. Locally (and as the first step in the build
process) only the fast and smoke tests are run.</p>
<p>Putting all the above together means that writing systems with two 
self- contained cores (the app domain itself and the test scenarios) 
easily lends itself to end-to-end testing that can be run on multiple 
configurations, to give confidence that the app works with all its 
components and dependencies in production - yet enable fast feedback
required for developers. The same tests can be run:</p>
<ul>
<li>directly against the core application with mocks, stubs, etc.</li>
<li>through the app's (http) UI via the given frameworks/libraries testing 
  tools (e.g.: <code>django.test.client.Client</code>) with an in-memory database</li>
<li>through selenium against the full stack</li>
</ul>
<p>And of course, we can mix and match - selenium against SQLite, etc.</p>
<p>While TDDing, one can run the tests only against the fast core, after
that is complete, we can run the relevant tests with the end-to-end
driver, fix any mistakes that occur, check in, and let the build server
run all the integrated tests (using existing build practices to 
achieve speed)!</p>
<h2 id="in-which-contexts-could-it-make-sense">In Which Contexts Could It Make Sense?</h2>
<p>Thank you for reading this far - assuming you didn't just scroll 
ahead :)</p>
<p>The below list is by no means exhaustive, and as mentioned in the
introduction, there might be alternative approaches (please, let me
know!) - it's not a coincidence this blog is called "Exercises in 
public learning"! </p>
<p>With that out of the way, here are some contexts where this approach
could make sense:</p>
<ul>
<li>
<p>Working with a team where the skills both for testing and for writing
    good code are (yet) missing (<a href="http://5whys.com/blog/the-3-maturity-stages-of-a-software-team-and-how-scrum-fails.html">Chaotic team phase</a>).</p>
<p>As the joke goes, the only way to eat the elephant is one bite at a 
time. Same goes for learning - people can be overwhelmed to make 
the mental jump from manual to automated testing - throwing in good
programming practices can be too much.</p>
<p>Getting started with end to end tests that have decoupled driver
methods (even if on the <code>TestCase</code> class itself) is a great start - by
the time the tests become slow, if the team is bought into the idea
of automated testing, it can be refactored towards a core domain -
and inside that domain there still doesn't have to be proper clean
code (one step at a time).</p>
<p>In brief: for slow, gradual improvement.</p>
</li>
<li>
<p>The app actually has multiple interfaces for the same thing.</p>
<p>It can be due to A/B testing, or simply to accommodate the different
needs of different users (e.g.: for a webshop - there is the public
shop, the internal UI geared at the company's sales people, and the
API), multi-platform application (e.g.: mobile and desktop web, iOS and 
Android), etc.</p>
<p>If you test the checkout process end-to-end, then running the same
set of tests against each UI makes sense too - a single set of tests
to maintain and you know immediately whether all features work 
across all the views.</p>
</li>
<li>
<p>Catching unexpected bugs.</p>
<p>There is a class of bugs that can be caught by rigor, but I do slip
occasionally, ending up in a place where the unit tests are all 
green, but the application itself doesn't actually work.</p>
<p>Some real life such bugs I have run into:</p>
<ul>
<li>forgetting to place the actual input element on the page</li>
<li>encoding-persistence issues - an utf-8 database with a column
    that is windows-1250 encoded is ... unexpected</li>
<li>synchronizing data with another database where after the 
    required mappings it turned out said other database truncates
    our data</li>
</ul>
<p>All of the above can be addressed retroactively via adding targeted
tests for that specific integration point, but if we are already
testing the corner cases (length, encoding, etc.) in our code, it is 
nicer not to have to learn about these "unknown unknowns" from 
production problems...</p>
</li>
<li>
<p>Finally some related posts from other people:</p>
<ul>
<li>Ayende has multiple posts: on <a href="http://ayende.com/blog/154273/limit-your-abstractions-and-how-do-you-handle-testing">swapping out the infrastructure</a>, <a href="http://ayende.com/blog/4218/scenario-driven-tests">separating assertions from tests</a>, and <a href="http://ayende.com/blog/4217/even-tests-has-got-to-justify-themselves">about which tests add value in his opinion</a></li>
<li><a href="http://codebetter.com/sebastienlambla/2013/07/11/unit-testing-is-out-vertical-slice-testing-is-in/">Sebastien Lambla on Vertical Testing</a></li>
</ul>
</li>
</ul>
<p>There is much more to be said about other <a href="/2013/10/28/going-beyond-regression-what-other-benefits-could-end-to-end-testing-provide/">benefits of end to end 
testing</a>, but this post is already too long, so that will have to wait
for <a href="/2013/10/28/going-beyond-regression-what-other-benefits-could-end-to-end-testing-provide/">another post</a> (while waiting, you can read <a href="http://codemanship.co.uk/parlezuml/blog/?postid=1183">Jason Gorman's 101 Uses for Polymorphic testing</a>)!</p>
<p>P.S.: I would like to thank (in (first name based) alphabetical order): 
<a href="https://twitter.com/ajmolenaar">Arjan Molenaar</a>,
<a href="https://twitter.com/sietstweets">Cirilo Wortel</a>,
<a href="http://douglassquirrel.com/">Douglas Squirrel</a>,
<a href="http://twitter.com/jtf">Jeffrey Frederick</a>,
<a href="https://twitter.com/KishenPanday">Kishen Simbhoedatpanday</a>,
<a href="http://twitter.com/marcoemrich">Marco Emrich</a>,
<a href="https://twitter.com/mfeathers">Michael Feathers</a>,
and of course my colleagues at <a href="http://www.paessler.com">Paessler AG</a> -  I much appreciate that you 
all listened to me while I tried to figure out how to explain this and 
gave feedback both about the content and the format (*). Thank you!</p>
<hr />
<p>(*) just to be crystal clear, this does not mean they endorsed it, 
just that they listened and gave feedback!</p>]]></content:encoded>
    </item>
    <item>
      <title>CITCON Turin Session Notes</title>
      <link>http://blog.zsoldosp.eu/2013/10/08/citcon-turin-session-notes/</link>
      <pubDate>Tue, 08 Oct 2013 13:30:00 CEST</pubDate>
      <category><![CDATA[conferences]]></category>
      <category><![CDATA[citcon]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">AWskB6wuNpU0UUAq1fII-TJYmS0=</guid>
      <description>CITCON Turin Session Notes</description>
      <content:encoded><![CDATA[<p>Finally got around to adding my notes for the <a href="/2013/09/30/citcon-turin-2013/">CITCON Turin 
2013</a> sessions to the 
<a href="http://citconf.com/wiki/index.php?title=CITCONEurope2013Sessions">wiki</a>.</p>
<ul>
<li><a href="http://citconf.com/wiki/index.php?title=Are_we_doing_improvement_wrong%3F">Are we doing improvement wrong?</a></li>
<li><a href="http://citconf.com/wiki/index.php?title=Continuous_Interruptions">Continuous Interruptions</a></li>
<li><a href="http://citconf.com/wiki/index.php?title=What_does_the_ideal_look_like%3F">What does the ideal look like?</a></li>
<li><a href="http://citconf.com/wiki/index.php?title=Low_level_test_code_/_library_bleeding_edge">Low level test code / library bleeding edge / beyond assertEquals</a></li>
<li><a href="http://citconf.com/wiki/index.php?title=Questions_on_the_right_level_and_amount_of_testing">What is code coverage good for? / Are we testing too much? / Does consolidated tree based test execution make sense?</a></li>
</ul>
<h2 id="notes-on-my-note-taking">Notes on my note taking</h2>
<p>... or what took me so long to add the notes? Why didn't I take notes 
directly in the conference wiki?</p>
<p>After my second attended conference I became an analog/offline attendee.
Note taking is much easier by hand - you can draw, arrow things into the
right place, and I find deciphering abbreviations and shorthand much 
easier in handwriting than in on-screen text.</p>
<p>I don't like having a screen separating me from other attendees (and 
cannot type on tablet keyboards effectively).</p>
<p>Having to type up my written notes later forces me to revisit ideas in
more detail than if I'm just re-reading old notes where I might skip 
parts thinking "sure, I know what that was". It's a mind trick to force 
me paying closer attention.</p>
<p>On top of that, I become much more careful about what I put down into 
the notes - sure, it's still rather raw and nowhere near blog post or
article quality, still much closer to raw notes/brain dumps. But it's
much improved compared to the raw notes I had in my notebook. Having the
handwritten pages only makes sure I know it is <em>not</em> DONE, which I might
fall into thinking had I written directly into the wiki.</p>
<p>Of course, that's just me, your mileage may vary!</p>]]></content:encoded>
    </item>
    <item>
      <title>CITCON Turin 2013</title>
      <link>http://blog.zsoldosp.eu/2013/09/30/citcon-turin-2013/</link>
      <pubDate>Mon, 30 Sep 2013 09:13:00 CEST</pubDate>
      <category><![CDATA[conferences]]></category>
      <category><![CDATA[citcon]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">HBw_qzJLfvKDJyuEPItoFPtvMx8=</guid>
      <description>CITCON Turin 2013</description>
      <content:encoded><![CDATA[<blockquote>
<p>Prior <a href="http://citconf.com/">CITCON</a> experience posts:</p>
<ul>
<li><a href="/2010/11/my-citcon-london-2010-experience.html">London 2010</a></li>
<li><a href="/2011/11/citcon-london-2011.html">London 2011</a></li>
<li><a href="http://citconf.com/budapest2012">Budapest 2012</a> - didn't get around
  to blog about it - since I was the local organizer, by the end of 
  the conf I depleted my energy reserves :)</li>
</ul>
</blockquote>
<p>Briefly about the conference - the open space format is still the best
thing since sliced bread as far conferences go, and CITCON still brings
together wonderfully smart people. Year after year I leave it being 
thankful for pointing me to questions (and answers) waaay outside the 
proverbial box....</p>
<h2 id="sessions-attended">Sessions attended</h2>
<p>This post does not contain <a href="/2013/10/08/citcon-turin-session-notes/">session notes</a> (I'm adding them to the 
<a href="http://citconf.com/wiki/">wiki</a>) but rather just tries to convey the atmosphere/feel
of the sessions.</p>
<ul>
<li>
<p><strong><a href="http://citconf.com/wiki/index.php?title=Are_we_doing_improvement_wrong%3F">Are we doing improvement wrong</a></strong>? Proposed by <a href="https://twitter.com/Jeffrey">Jeffrey</a>, 
  inspired by the <a href="http://www.amazon.com/Toyota-Kata-Managing-Improvement-Adaptiveness/dp/0071635238/">Toyota Kata</a> book, it described the two 
  Katas, and illustrated why measuring improvement by the output 
  (results) only can lead to missed improvement opportunities (e.g.: the
  book describes that before an improvement effort, line managers were 
  called in for troubleshooting 1000 times a shift, which then decreases
  two 700 a shift. The leadership's response was that this means either</p>
<ul>
<li>people are hiding or working around failures, which is bad</li>
<li>people stopped improving, which is bad too</li>
</ul>
</li>
</ul>
<p>so they adjusted the workload to enable taking full advantage of
  the bandwidth of 1000 improvements/introspections the factory was
  capable of.</p>
<ul>
<li>
<p><strong><a href="http://citconf.com/wiki/index.php?title=Continuous_Interruptions">Continuous interruptions</a></strong> Proposed by <a href="https://twitter.com/KishenPanday">Kishen</a>, we dug deep
  into how interruptions can be a wonderful tool for knowledge sharing,
  mentoring and how they hide (or to be more precise, expose) risk 
  factors. I wish I had mentioned the urban legend about <a href="https://en.wikipedia.org/wiki/QWERTY#cite_ref-5">the QWERTY 
  keyboard layout's design origin</a>, but the point about 
  interruptions slowing you down enough to force taking a step back 
  didn't need analogies. And it seems we all have colleagues whose cell
  phones only ring when their owners, unlike the phones, are not 
  present...</p>
</li>
<li>
<p><strong><a href="http://citconf.com/wiki/index.php?title=What_does_the_ideal_look_like%3F">What does the ideal software development process look like?</a></strong> 
  proposed by <a href="https://twitter.com/aparker42">Andrew Parker</a>, closely linked to the first
  session of the day about improvement (towards the ideal one to one
  flow) is probably the one session that I left with more questions
  than answers - not just about the topic, or its conclusions (shorten
  the cycle time (effort) required for going from idea to getting
  feedback), but even about the open spaces framework (what if the 
  scribe wants to apply the law of two feet?).</p>
</li>
<li>
<p><strong><a href="http://citconf.com/wiki/index.php?title=Low_level_test_code_/_library_bleeding_edge">Low level unit testing/assertion code patterns</a></strong> proposed by me,
  driven by my desire to learn what new ideas are present in this
  space. While I haven't learned of any new patterns, I left with a 
  much better understanding of how language embedded and enforced pre-
  and post-conditions (or code contracts in the C# world) can actually
  been tested, contrary to my initial assumption</p>
</li>
<li>
<p><strong><a href="http://citconf.com/wiki/index.php?title=Questions_on_the_right_level_and_amount_of_testing">Are we testing too much? / What's the point of code coverage? /
  Would a Test Tree Builder and Executor make sense?</a></strong> - this was a 
  merge of three topics, proposed by <a href="https://twitter.com/KishenPanday">Kishen</a>, <a href="https://twitter.com/ajmolenaar">Arjan</a>,
  and myself. It was the smallest session in attendance (it was the
  three of us and <a href="https://twitter.com/sietstweets">Cirilo</a>, with <a href="https://twitter.com/Jeffrey">Jeffrey</a> also popping by
  towards the end), but true to the spirit of open spaces, we were
  totally engaged. Plus <a href="https://twitter.com/Jeffrey">Jeffrey</a> demonstrated the need for more
  effectively transmitting information (when we brought him up to speed
  of what is being discussed, he just said "CITCON Australia 2009") or
  prior art - there is a kind of generational gap that exists between 
  programmer generations that could benefit from a few more bridges
  (though leaving enough of a divide so that people will still work on
  and solve problems that were previously declared "unsolvable"!).</p>
</li>
</ul>
<p>Had I not proposed any sessions, I would have loved to attend <em><a href="https://twitter.com/sf105">Steve 
Freeman</a>'s TDD Clinic</em> - it's always a pleasure to see great 
people perform, not to mention the learning opportunity. I also would
have liked to listen to <em><a href="https://twitter.com/ivanrmoore">Ivan Moore</a> describing the build setup
they have for their multi componented system</em> at work - I faced that 
problem years ago, topped with the plugin compatibility across multiple
versions problem, so would have loved to see what they did. And next 
time I'm in Budapest, I'll probably try to visit <a href="http://prezi.com">Prezi</a> again 
in case Jayson is around so I could take another look at their <code>fkt</code> 
system (and to listen to the <em><code>please</code>, <code>simply</code>, and <code>fkt</code> machine 
provisioning evolution story</em> again).  Luckily, <a href="https://twitter.com/zeljkofilipin">Zejko</a>'s 
session's about how <a href="https://wikipedia.org/">Wikipedia</a> tests there system is easy to
find online, since - like everything else <a href="https://wikipedia.org/">Wikipedia</a> does -,
it is open. But as I always say, it's so much better to leave a conf 
with too many good sessions than one with too little...</p>
<p>Another great aspect of CITCON is the dinner afterwards - even though
it splits into multiple small groups, it's real nice to talk with people
directly, both about non-tech (like explaining why it would
make a ton of sense for the Budapest Opera House to organize a summer
Opera festival) and tech (thanks to all who listened to my pet project 
ideas, and gave really useful feedback!)</p>
<p>The reunion-like feeling <a href="https://twitter.com/PaulJulius">PJ</a> mentioned during his opening remarks
was true for me too, but sadly I haven't prepared enough - I should have
organized more explicit catch-up sessions outside the conference, for I
couldn't chat with everyone I wanted to in enough depth - hard to do
when we are running additional sessions even during the lunch break!
Plus of course one doesn't want to give the conference itself an 
exclusive atmosphere - I still vividly remember my nervousness at my 
first CITCON, trying to overcome the inherent shyness to talk to people,
attempting to join their conversations...</p>
<p>In closing, I would like to thank <a href="https://twitter.com/capotribu">Marco Abis</a> again, who was
the remote-local organizer of the conference, for making it happen. I 
met wonderful new people, and learned (or refined my understanding) of 
many topics!</p>
<p>During the coming days, I will be adding my session notes to the 
<a href="http://citconf.com/wiki/">conf wiki</a> coming days, and once I digested all the feedback I 
got during and outside the sessions, I will be writing up the <em>Tree 
Optimized Test Runner</em> and the <em>app-test DSLs to have multiple drivers
for a single TestCase</em> ideas in more detail.</p>]]></content:encoded>
    </item>
    <item>
      <title>Teach me refactoring from my commits!</title>
      <link>http://blog.zsoldosp.eu/2013/09/27/teach-me-refactoring-from-my-commits/</link>
      <pubDate>Fri, 27 Sep 2013 09:40:00 CEST</pubDate>
      <category><![CDATA[things i wish existed]]></category>
      <category><![CDATA[teaching]]></category>
      <category><![CDATA[untested ideas]]></category>
      <category><![CDATA[version control]]></category>
      <category><![CDATA[refactoring]]></category>
      <guid isPermaLink="false">GZ4JOnYZvQe5D8VUfKUh6eJAlkw=</guid>
      <description>Teach me refactoring from my commits!</description>
      <content:encoded><![CDATA[<p>I find it hard to learn purely by abstract theory - I need practical 
examples to illustrate the theory I just learned. I also need practice,
and preferably, supervised practice, so my mistakes can be caught early
and/or more efficient ways can be shown to achieve the same thing I just
did.</p>
<p>With this background, it's not surprising that when I <a href="http://episodes.gitminutes.com/2013/06/gitminutes-14-pablo-santos-on.html">heard about a 
product that started to do semantic diffs for version 
control</a> I was reminded of the <a href="https://sc2010subs.wordpress.com/2010/08/13/refactoring-golf-dave-cleal-ivan-moore/">Refactoring 
Golf</a> concept from the first <a href="http://www.codemanship.co.uk/parlezuml/softwarecraftsmanship/">Software Craftsmanship 
London</a> conference - and the two ideas just clicked into this
great (ok, I'm biased) idea to try to derive the most efficient
refactoring steps for that particular commit I just made.</p>
<p>The pieces required for this project are all already in place:</p>
<ul>
<li>we have parsers for languages, and many are available as libraries to
  traverse <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">ASTs</a></li>
<li>most version control systems have libraries to read from them</li>
<li>there are tons of well-defined refactorings known, that can be used
  as operations in the transformations from state <code>A</code> to <code>B</code></li>
<li>optimization algorithms are plentiful - for a proof of concept, the
  <a href="https://en.wikipedia.org/wiki/String_distance">String Distance</a> Transformation algorithm could be used</li>
</ul>
<p>Thus such a program script could be added as a post commit hook, or 
simply could be run on the workspace copy, using the diff against last
committed version, and it could tell me that I might have:</p>
<ol>
<li>renamed variable <code>login</code> to <code>username</code></li>
<li>converted <code>username</code> from local variable to method parameter</li>
<li>extracted method <code>lock_customer_acocunt</code> from method <code>login</code></li>
</ol>
<p>I'm pretty positive even experienced refactoring practitioners could 
learn new tricks, and newbies would be delivered concrete refactoring
examples tailored to their very codebase.</p>
<p>Please, someone with enough free time, go and make such an app!</p>
<p>Does this idea make sense for you too, or just me? Let me know via email
(hello at site domain) or on twitter (<a href="https://twitter.com/zsepi">@zsepi</a>)!</p>]]></content:encoded>
    </item>
    <item>
      <title>Quick script to help reporting bugs for python</title>
      <link>http://blog.zsoldosp.eu/2013/09/11/quick-script-to-help-reporting-bugs-for-python/</link>
      <pubDate>Wed, 11 Sep 2013 17:00:00 CEST</pubDate>
      <category><![CDATA[code]]></category>
      <category><![CDATA[note to self]]></category>
      <category><![CDATA[bash]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">-y0sMmjTXW82o3McTP9I6l_Hh4k=</guid>
      <description>Quick script to help reporting bugs for python</description>
      <content:encoded><![CDATA[<div class="document">
<p>While poking around the
<a class="reference external" href="https://pypi.python.org/pypi/testrepository/">testrepository</a>
package I ran into the cryptic error message of <strong>'unicodeescape'
codec can't decode bytes in position 56-57: truncated \uXXXX escape</strong>.
I set out to reproduce the bug, but that is of course an iterative
process, like anything else in coding, so I set out to script it. Since
I expect I'll need this again, and someone else might need it too,
I'm recording it here.</p>
<div class="note">
<p class="first admonition-title">Note</p>
<p>I eventually figured out the problem was that <a class="reference external" href="http://testrepository.readthedocs.org/en/latest/MANUAL.html#python">the recommended
default for testrepository</a>
has a different command line behavior from the built in unittest's
runner:</p>
<blockquote>
<ul class="simple">
<li><tt class="docutils literal">python <span class="pre">-m</span> unittest discover bugrepro</tt></li>
<li><tt class="docutils literal">testr run bugrepro</tt> doesn't get translated to the discover
root, but into <tt class="docutils literal">LISTOPT</tt> variable (<tt class="docutils literal">python <span class="pre">-m</span> subunit.run
discover . $LISTOPT $IDOPTION</tt>)</li>
</ul>
</blockquote>
<p class="last">Sure, a nicer exception message would have been nice.</p>
</div>
<div class="section" id="my-environment">
<h1>My Environment</h1>
<p>While for serious development I use Linux VMs, for explorations/hobbies,
I use the base Windows 7 on my command line from git-bash - it's enough
for basic scripting things, plus I tend to use git anyway, and I don't
like Powershell.</p>
</div>
<div class="section" id="the-script">
<h1>The script</h1>
<pre class="code bash literal-block">
<span class="c">#!/bin/sh
</span><span class="k">function </span>d<span class="o">()</span> <span class="o">{</span>
    <span class="nb">echo</span> <span class="s2">&quot;\$ $*&quot;</span>
    <span class="nv">$*</span>
<span class="o">}</span>

<span class="k">function </span>win_info<span class="o">()</span> <span class="o">{</span>
    systeminfo | grep <span class="s2">&quot;\(OS Name\|OS Manufacturer\|System Type\|Locale\)&quot;</span>
<span class="o">}</span>

<span class="nv">REPRO_FOLDER</span><span class="o">=</span>bugrepro
d win_info
d python --version
d pip freeze
d git --version
d grep ^ -nH <span class="sb">`</span>find <span class="nv">$REPRO_FOLDER</span> -name <span class="se">\*</span>.py<span class="sb">`</span>
d python -m unittest discover <span class="nv">$REPRO_FOLDER</span>
d ls .testr* -l
d cat .testr.conf
d testr run <span class="nv">$REPRO_FOLDER</span>
d testr run
</pre>
<p>Running <tt class="docutils literal">./bugrepro.sh <span class="pre">2&gt;&amp;1</span> | tee bugrepro.txt&nbsp; &gt; /dev/null</tt> produces
the following output (cropped, you can see
<a class="reference external" href="/snippets/bugrepro.txt">the full output here</a>):</p>
<pre class="literal-block">
$ win_info
OS Name:                   Microsoft Windows 7 Professional 
OS Manufacturer:           Microsoft Corporation
System Type:               x64-based PC
System Locale:             en-us;English (United States)
Input Locale:              en-us;English (United States)
$ python --version
Python 2.7.4
$ pip freeze
extras==0.0.3

</pre>
</div>
<div class="section" id="things-i-learned">
<h1>Things I learned</h1>
<p>While this took somewhat longer than expected (and writing this
post wasn't even planned!) and I haven't even reported the actual
bug yet (Yak shaving...), but I don't mind - especially because I
did all this while recovering from a nasty cold :)</p>
<ul class="simple">
<li>for <tt class="docutils literal">cmd.exe</tt>, the <tt class="docutils literal">ver</tt> and <tt class="docutils literal">systeminfo</tt> commands are pretty neat
and <a class="reference external" href="http://www.windows7password.net/all-windows-7-commands-cmd-exe/">there are more commands</a>:
type <tt class="docutils literal">help</tt></li>
<li>wrote my first blog post in
<a class="reference external" href="http://docutils.sourceforge.net/rst.html">reStructuredText</a>
since it's a better fit for including snippets (<a class="reference external" href="/2010/08/executable-documentation.html/">executable
documentation</a> is a pet peeve of mine!)</li>
</ul>
<p><strong>Open Questions</strong> (aka: do I want to shave further yaks?!):</p>
<ul>
<li><p class="first"><tt class="docutils literal">cmd.exe /C</tt> doesn't seem to behave as one would expect it when
invoked from git-bash (msysgit, 1.8.1) - it doesn't exit and the
execution to continue requires an <tt class="docutils literal">exit</tt> command!</p>
</li>
<li><p class="first">I always want to do
<a class="reference external" href="/2013/07/25/some-metaprogramming-reflection-in-bash/">metaprogramming in bash</a>
- how could I display
the body of a bash function? I'm thinking of something similar to
what one does with alias</p>
<pre class="code bash literal-block">
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">foo</span><span class="o">=</span><span class="s1">'echo foo'</span>
<span class="nv">$ </span>foo
foo
<span class="nv">$ </span><span class="nb">alias </span>foo
<span class="nb">alias </span><span class="nv">foo</span><span class="o">=</span><span class="s1">'echo foo'</span>
</pre>
</li>
<li><p class="first">is there a better way for passing arguments in bash? I ended up doing
<tt class="docutils literal">grep ^</tt> because I went crazy trying to escape
<tt class="docutils literal"><span class="pre">find...</span> <span class="pre">-exec...\;</span></tt>.
and making the script use <tt class="docutils literal"><span class="pre">#!/bin/bash</span> <span class="pre">-x</span></tt> would be an overkill
here, and I just want to echo back the command that was executed...</p>
</li>
</ul>
</div>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>Own your data (or why did I move away from Blogger and WordPress?)</title>
      <link>http://blog.zsoldosp.eu/2013/08/04/own-your-data-or-why-did-i-move-away-from-blogger-and-wordpress/</link>
      <pubDate>Sun, 04 Aug 2013 14:25:00 CEST</pubDate>
      <category><![CDATA[blog]]></category>
      <category><![CDATA[outdoors]]></category>
      <category><![CDATA[data]]></category>
      <category><![CDATA[ownership]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">8UAjTLJV0td1NxR0DNBSZhVVots=</guid>
      <description>Own your data (or why did I move away from Blogger and WordPress?)</description>
      <content:encoded><![CDATA[<p>This blog used to be two separate blogs, hosted at 
<a href="http://blogger.com">Blogger</a> and <a href="http://wordpress.com">WordPress.com</a>,
respectively. I've gone through some trouble to migrate their content,
hopefully without breaking urls to this <a href="http://blogofile.com">Blogofile</a> 
based setup. In the process, I have lost a considerable number of 
features and conveniences - so why did I do this?</p>
<h2 id="owning-my-data-and-platform">Owning my data and platform</h2>
<p>As the saying goes, there is no such thing as a free lunch (or put more
bluntly, if you are not paying for it, <em>you</em> are the product being 
sold). A prime example is <a href="http://wordpress.com">WordPress.com</a>, which reserves the
right to display ads on your freely hosted blog, while <a href="http://blogger.com">Blogger</a>
probably enhances their advertisement profile of you - I don't know.</p>
<p>Even if these platforms don't do anything bad at the moment, they can
pretty much change the features available to you, or any other aspects
of their terms of service - remember that story about the 
<a href="http://news.cnet.com/8301-1023_3-57560370-93/instagram-rolls-back-terms-of-service-after-ownership-dustup/">Instagram ToS change regarding commercial use of your photos</a>?
Sure, it turned out to be a misunderstanding and/or they backed down,
but theoretically they can do it.</p>
<p>Of course, this wasn't a concern when I started out with blogging, but 
certainly is something to consider now that I am nearing post #42. </p>
<p>These considerations are of course applicable for other service 
providers beyond blogging, e.g.:</p>
<ul>
<li>(sports) tracking applications - while I have not yet gotten around 
  to building up a website like <a href="http://www.susi-ralf.de/index.html">Suzi &amp; Ralf</a>, but I know 
  eventually I will want to create something with the trails of all the
  places I've been to, whether for fun or for an anniversary gift or
  similar - and most sites make it rather hard to export your data 
  conveniently (<a href="http://endomondo.com">endomondo</a> is particularly annoying, so I'm 
  real grateful for the easy zip-export of <a href="http://runkeeper.com">runkeeper</a>!)</li>
<li>social networks - does <a href="http://linkedin.com">LinkedIn</a>, <a href="http://facebook.com">Facebook</a>, 
  <a href="http://xing.com">Xing</a>, etc. allow you to easily export your contacts and their
  contact details? I would be pretty upset to find myself without a 
  personal copy of that data</li>
</ul>
<p>Of course, I keep using services hosted by others, but I try to make 
sure I use one with a friendly <a href="http://www.dataliberation.org/">data liberation</a>
policy!</p>
<h2 id="other-considerations">Other considerations</h2>
<ul>
<li><strong>backup</strong> - sure, it's almost a repeat of the prior point, but worth 
  noting. It doesn't happen as often as before, but there is always the
  possibility of <a href="http://blog.theoldreader.com/post/56209408824/important-update">data loss or service outage</a></li>
<li><strong>version control</strong> - being a software developer, this is almost 
  second nature to me - it's incredibly liberating to be able to throw
  all my changes away and go back to a previous, known good version of
  a post draft.</li>
<li><strong>offline authoring</strong> - I do a lot of my writing and hobby coding 
  during my train commute, with spotty internet connection at best.
  Working locally on my laptop with my favorite text editor beats any
  online editor widget. </li>
<li><strong>full customizations</strong> - sure, probably there is a WordPress plugin
  for anything I would want to do, but for a lot of the small checks, 
  it takes longer to find, learn, and configure the one I need than
  to implement it in <a href="http://python.org">python</a> - e.g.: checking the site for
  broken links, custom reports, etc. I should probably mention the html
  template customizations here too, though you might be able to tell
  that is not yet the highest priority for me :)</li>
</ul>]]></content:encoded>
    </item>
    <item>
      <title>Some Metaprogramming (Reflection) In Bash</title>
      <link>http://blog.zsoldosp.eu/2013/07/25/some-metaprogramming-reflection-in-bash/</link>
      <pubDate>Thu, 25 Jul 2013 08:18:00 CEST</pubDate>
      <category><![CDATA[code]]></category>
      <category><![CDATA[metaprogramming]]></category>
      <category><![CDATA[bash]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">SrLBQ0AP18Vcd0lyROK5o6cmGI0=</guid>
      <description>Some Metaprogramming (Reflection) In Bash</description>
      <content:encoded><![CDATA[<p>I needed to write a function in bash that would set an environment 
variable to that value, unless the variable has been already set. 
This is a typical metaprogramming (reflection, introspection, etc.) 
task. </p>
<p>However, searching for the terms I know (reflection, metaprogramming) 
did not yield any bash results, since the bash terminology is <em>variable
variable</em> or <em>dereferencing</em>. I hope the title of this post will help
other non-native bash script writers searching for the "wrong" keywords!</p>
<p>The trick is the <code>${!&lt;variable name&gt;}</code> construct - it will be interpreted
as <code>${&lt;variable name's value&gt;}</code>. An example</p>
<pre><code>$ a="aaaaa"
$ b="bbbbb"
$ echo $a
aaaaa
$ echo $b
bbbbb
$ variable_name="a"
$ echo ${!variable_name}
aaaaa
$ variable_name="b"
$ echo ${!variable_name}
bbbbb
</code></pre>
<p>Of course, I could only find it offline (thanks, <a href="https://www.xing.com/profiles/Dieter_Loskarn">Dieter</a>!). 
Armed with this kowledge, the function itself becomes easy -</p>
<pre><code>function env_or_default() {
    name=$1
    default=$2
    if [[ ${!name} == "" ]]; then
        echo "no value set for $name, setting it to default value $default"
        export $name=$default
    else
        echo "value for $name was passed in from the environment, it's value is ${!name}"
    fi
}
</code></pre>
<p>Obviously, the <code>echo</code> lines are there just for illustration.</p>
<pre><code>$ env_or_default NOT_SET not-set-default-value
no value set for NOT_SET, setting it to default value not-set-default-value
$ export ALREADY_SET=already-has-value
$ env_or_default ALREADY_SET already-set-default-value
value for ALREADY_SET was passed in from the environment, it's value is already- has-value
$ echo $NOT_SET
not-set-default-value
$ echo $ALREADY_SET
already-has-value
</code></pre>
<p>Happy scripting! </p>
<p>P.S.: Krzysztof Wilczynski showed another <a href="https://gist.github.com/kwilczynski/5877621">trick to do 
this</a>:</p>
<pre><code>random_file_name() {
    local __return=$1
    eval $__return="'$(date +"$(basename -- "$0")_%s_${RANDOM}_$$")'"
}

random_file_name FILE_NAME
echo $FILE_NAME
</code></pre>]]></content:encoded>
    </item>
    <item>
      <title>Opening the 2013 paddling season on the Kocher</title>
      <link>http://blog.zsoldosp.eu/2013/03/10/opening-the-2013-paddling-season-on-the-kocher/</link>
      <pubDate>Sun, 10 Mar 2013 17:08:36 CET</pubDate>
      <category><![CDATA[outdoors]]></category>
      <category><![CDATA[canoe]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2013/03/10/opening-the-2013-paddling-season-on-the-kocher/</guid>
      <description>Opening the 2013 paddling season on the Kocher</description>
      <content:encoded><![CDATA[
I've just posted a brief description of our first trip of the season over at the <a href="http://www.songofthepaddle.co.uk/forum/showthread.php?40272-Opening-the-2013-season-on-the-Kocher-Braunsbach-to-K%FCnzelsau&amp;p=465323">Song of the Paddle</a> forum, check it out!]]></content:encoded>
    </item>
  </channel>
</rss>
