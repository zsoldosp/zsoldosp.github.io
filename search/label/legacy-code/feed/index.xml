<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Do. Reflect. Learn. Repeat!</title>
    <link>http://blog.zsoldosp.eu</link>
    <description>Excercises in public learning</description>
    <pubDate>Tue, 19 Apr 2016 10:39:21 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>My first Code Retreat - Legacy Code Retreat in Frankfurt on Sep 15, 2012</title>
      <link>http://blog.zsoldosp.eu/2012/09/my-first-code-retreat-legacy-code.html</link>
      <pubDate>Wed, 19 Sep 2012 19:44:00 CEST</pubDate>
      <category><![CDATA[software]]></category>
      <category><![CDATA[code retreat]]></category>
      <category><![CDATA[legacy code]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2012/09/my-first-code-retreat-legacy-code.html</guid>
      <description>My first Code Retreat - Legacy Code Retreat in Frankfurt on Sep 15, 2012</description>
      <content:encoded><![CDATA[
          
<blockquote><p>If you are not familiar with the concept of a  <a href="http://coderetreat.org/">code retreat</a>, listen to this  <a href="http://www.dotnetrocks.com/default.aspx?showNum=728">podcast</a> (or read the  <a href="http://s3.amazonaws.com/dnr/dotnetrocks_0728_corey_haines.pdf">transcript</a>).</p></blockquote><p>While I knew about <a href="http://coderetreat.org/">Code Retreats</a> for a while, this  was the first I actually managed to attend). It was organized by the  <a href="http://www.softwerkskammer.de/">German Software Craftsmanship community</a> group, hosted by <a href="http://namics.com">Namics</a>, and facilitated by <a href="https://twitter.com/NicoleRauch">Nicole Rauch</a> and <a href="https://twitter.com/leiderleider">Andreas Leidig</a>. And it was great, thanks to everyone involved in putting up the event!</p><p>The <a href="http://www.coderetreat-rhein-main.com/learnmore-legacy">format has been described by others</a>, so I won't cover that. I have to say though that I really like the format and I wish I started socializing (in software related matters) first at a  code retreat instead of conferences or usergroups - the format of the  event guarantees one doesn't have to worry about uncomfortable silences to be filled with smalltalk. The day starts with coding, the retrospective is group talk, and with the exception of the lunch, the breaks are only five minutes long, and you are searching for the next programming pair  during that time anyway. Great way to get more comfortable interacting  with strangers about software! (And if you do want to socialize, just come early for breakfast and stay after the event).</p><h2 id="i_wonder_if_being_familiar_with_automated_testing_is_a_pre-requisite">I wonder if being familiar with automated testing is a pre-requisite</h2><p>My assumption is that one could attend a legacy code retreat even if  (s)he has no experience with automated testing, since</p><ul><li>You could learn the basics of testing from the pairs you are working   with</li><li>You can see it applied <em>in the real world</em>. The most common objection   I hear from people recently introduced to automated testing/TDD is that    it might work on greenfield projects, but cannot be applied on their    existing project</li></ul><p>So if you are (or know of someone who is) a person who attended such a  code retreat with no prior testing experience, please let me know - I  would love to know whether the above hypothesis matches your experience! Unfortunately all my pairs had prior experience, so it's still just a hypothesis.</p><h2 id="iteration_impressions_lessons_learned">Iteration impressions, lessons learned</h2><ul><li>Dynamic language IDEs still have a long way to go, so for now I'll    probably stick to Vim for python</li><li>While it's interesting to take a guided tour of a language you don't   know, the focus of the codebase is not on datastructures (only uses   lists/arrays) and thus you only catch a glimpse of the language. I'll   have to attend a normal code retreat to see whether this would be    different there</li><li>Giving a language demo is interesting, and you learn a lot about the   language too. People new to a language tend to ask questions about    things you take for granted, yet you may not know the answer to</li><li>Taking baby steps and not assuming anything is a Good Thing ™ - the   codebase is devious one, crafted with care to make you trip over. I.e.:   it is a proper legacy codebase, despite its small size!</li><li>The "never assume" advice holds especially as you move between    iterations. During one iteration we made a mistake that wasn't caught by    the regression tests. Since in the previous iteration (with another    pair) we had 100% (line) coverage, the fact that in the next    iteration we might not have that didn't occur to me...</li><li>Discipline is hard. I was totally carried away refactoring during the   last iteration. I had this craving to actually make progress with the   refactoring, and I caught myself saying things "were we responsible   coders, we would now stop to write some tests, but let's just move on   now", as well as tugging multiple pieces of the spaghetti at the same   time. While here I might be forgiven (after all, the last iteration    was a free to choose what to do (with) this codebase), it's an   important reminder that I should watch myself at work - I would have   never expected myself to get so off track in a matter of 10-15 minutes.   And I used to pride myself that I realize when I'm in a dead end and   have no trouble throwing away code to start from the last known good   state!</li><li>The code retreat format is great for teaching people the importance of   prototypes, I will keep that in mind for the future. During the    functional iteration we haven't made much progress, but on the train    home I did a quick experiment to start making it functional from the   outside in, starting at the main() method, introducing the GameState   as a subclass of Game, and each step returning a new GameState (while   still modifying the old game state, since the refactoring was    incomplete, as it usually is the case). This approach didn't occur to    me the first time, and had I not started from a clean slate, I would   not have thought of it if I were to continue where I left off the    previous attempt.</li><li>While the facilitators keep going around, we didn't always get deep    into the issues they commented on (e.g.: I think if the test case and    the test name express clearly the domain and the scenario, it is   totally fine to use a variable called <em>sut</em>, etc.). </li><li>However, there is a lot of time available to discuss with your pair,   not having to worry whether or not the code will be finished, which    is great. One caveat is that you do have a time limit on the    discussion, since you don't want to bore your pair and want to    actually write code, so you are forced to condense your thoughts.    Luckily, this limit is not as bad as <a href="https://twitter.com">twitter</a>'s</li><li>Theory vs. practice, a.k.a. talking the talk vs. walking the walk.    I've been guilty of this myself, describing how my ideal test case    would look like in theory, and what guiding principles I follow while   writing an actual test case. Then the pair politely points out that the    theory is great, but what we have here in the code is not a    manifestation of those principles...</li></ul><h2 id="the_iteration_i_wish_was_there_-_working_towards_a_change_request">The Iteration I wish was there - working towards a change request</h2><p>Each iteration had a different focus, and I assume that there isn't a static final (pun intended) list of possible restrictions and it evolves. So despite this being my first ever code retreat and being told that  these ideas wouldn't fit the format, I'm documenting them here, so that I can refer back to it after my next code retreats to see whether I still feel the same about these, since now I think they would be similar  restrictions like during the traditional code retreat when one is not  allowed to speak or use <em>if</em> statements in the code.</p><p>I really missed having a clear functional goal for the iterations, since one usually refactors legacy code when some new feature/enhancement is  needed - and it has a huge impact on how one approaches a refactoring.</p><p>One mistake I have (seen) made when working with legacy code is going on  a <strong>refactoring spree</strong>, touching parts of the codebase which  we don't  need to change. The danger of it is that we can easily code ourselves  into a corner for days and slip on the original delivery. If it ain't  broken, don't fix it (and this doesn't contradict the  <a href="http://programmer.97things.oreilly.com/wiki/index.php/The_Boy_Scout_Rule">boyscout rule</a>). This issue has been exposed during the iterations, many of us refactored one part of the application that  wasn't business logic heavy, but was a low hanging fruit. While one  iteration wouldn't be enough time to finish testing that part, the  conversation around it (what test cases would be needed to provide  sufficient code coverage, what's the minimum refactoring we need to do  to achieve that, etc.).</p><p>I raised it during the final retrospective, and people agree it's an important aspect, but they suggested it's not fit for the format of the code retreat.</p><p>The other great benefit of having a clear goal is that they demonstrate how <strong>fragile</strong> the <strong>regression characterization tests</strong> can be. A  neat little change request to the core business logic would have left  us without the safety net again, and would have made us think back to  the previous iterations when we felt skipping writing a specific test  is safe. While everyone knows it, that doesn't mean we wouldn't fall  victim to it..</p><p>And if you prefer to see a concrete example, instead of just reading  through this abstract text, I have something like the <a href="http://anarchycreek.com/doubledawgdare-series/">Double Dawg  Dare</a> in mind.</p><h2 id="some_technical_notes_for_attending_a_code_retreat">Some technical notes for attending a code retreat:</h2><ul><li>doublecheck with the organizers what you'll need to attend. They    probably plan to send out a reminder/notification email before the   event, but I so rarely use my laptop in an online environment that   their notice was too late for me to actually prepare my laptop for   the event.</li><li>know your settings &amp; IDE. There are a ton of yaks to be shaved, and   many minutes have been wasted by setting things up. It doesn't take   away from the experience, but it did stress me a bit the first time</li><li><p>either know how to use git, or just create two copies of the codebase   so you can easily revert to a clean codebase after the sessions. We    had some problems with this.</p><p>git clean -x -f -n # remove -n to really remove them   git reset HEAD . # remove everything from the changelist in case you added it   git checkout -- . # revert everything below the </p></li><li><p>bring a USB stick, and if you are not using your own laptop during all    the sessions, make a copy of the golden master textfile onto it after    each of your sessions in a new programming language (my laptop was    only used during the first and the last iteration, so for the last we   had no sample output textfile we could work against, and it took some   time to obtain it.</p></li><li>bring your own keyboard and know how to change a mac/linux/windows    machine's keyboard layout (or install one). I have not been typing in    a number of sessions because of this (try typing on a German mac    keyboard, when you are used to windows US layout!)</li></ul><h2 id="in_summary">In Summary</h2><p>It's a great event, you meet great people, and I would be surprised if  you came away from a code retreat not having learnt anything new.</p>
<hr><ol>
<li id="1">
    <strong><a href="http://www.blogger.com/profile/06671468907643091304">Adrian Bolboaca</strong></a> on <em>2012/09/21 10:44:14</em>: Thanks for the great write-up.<br/><br/>I have a kind of an answer for why I don't get to that session of change request. When I thought about the legacy code retreat and added a couple of sessions I wanted to have a more natural flow. I wanted to have this session also, sometimes in the end of the day. But as a facilitator I saw that the attendees do not really know the techniques so we are stuck into explaining the basics that they need in order to be able to handle a change request. During all the legacy code retreats I facilitated maybe the 7th iteration would have been the "change request constraint". <br/>I e-met Andreas and Nicole a couple early this year when we had a skype call about the legacy code retreat. Then I met them at the Socrates conference this year. I'm sure they are doing an excellent job as facilitators, and maybe they have some answers to this. My guess is that we need more legacy code retreats happening and only after a while when the attendees know better the basics we can start and introduce this session. Or maybe we can find together a solution on improving the current format.
<ol>
<li id="1-1">
    <strong><a href="http://pboop.wordpress.com/">pboop</strong></a> on <em>2012/09/23 16:44:45</em>: I agree with you. In my opinion a leagcy code retreat is about HOW to change the code not WHY or WHICH WAY in order to open room for a new requirement.<br/><br/>Every participant is free to let her/his imagination grow after (or even during) the retreat and play around with the code base, inventing new requirements and so on.
</li><li id="1-2">
    <strong><a href="/">Peter Zsoldos</strong></a> on <em>2012/09/30 17:11:58</em>: Thanks for the comment and sorry for the late followup.<br/><br/>I didn't intend that section as a criticism for the facilitators. Since it can be misread, I would appreciate if you could point out where and how, so I can correct it to avoid anyone else misunderstanding my intent (re-reading my post didn't help, I'm afraid I have too much context about what I wanted to say).
</li><li id="1-3">
    <strong><a href="/">Peter Zsoldos</strong></a> on <em>2012/09/30 17:12:58</em>: I don't know what the exact goal was behind creating the legacy coderetreat format. But I have always preferred learning not just a practice, but also its underpinning ideas and the limits of it. While I can practice refactoring on my own, there may not be someone around pointing out that not everything needs to be refactored. Both are important and have their places, and we seem to disagree about the latter. My thinking is influenced by seeing people (myself included) overdoing/overvaluing the latest pattern/practice they have came across (HelloWorldProxyFactoryImpl), without knowing the limits of their usefulness and knowing the difference between understanding something in theory versus doing that in practice - being told something is brittle/unreliable and understanding it on an intellectual level is very different from actually experiencing it. The latter tends to be easier to remember :)<br/><br/>But I might have fallen victim to offering a solution instead of raising a question. If the Nuremberg global code retreat will be a success, and there will be more following it, I'll be happy to immerse myself deeper into the code retreat community and see how I feel about this original idea after some time - one of the motivations for posting it was so that I can come back and revisit it later.
</li></ol></li></ol>

          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2012/09/my-first-code-retreat-legacy-code.html">My first Code Retreat - Legacy Code Retreat in Frankfurt on Sep 15, 2012</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>Data Migrations As Acceptance Tests</title>
      <link>http://blog.zsoldosp.eu/2011/11/data-migrations-as-acceptance-tests.html</link>
      <pubDate>Fri, 04 Nov 2011 09:23:00 CET</pubDate>
      <category><![CDATA[rewrite]]></category>
      <category><![CDATA[data migration]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[tdd]]></category>
      <category><![CDATA[software]]></category>
      <category><![CDATA[approach]]></category>
      <category><![CDATA[legacy code]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2011/11/data-migrations-as-acceptance-tests.html</guid>
      <description>Data Migrations As Acceptance Tests</description>
      <content:encoded><![CDATA[
          
<p>While I have previously said that <a href="/2011/09/testing-strategy-on-migration-projects.html">on migration projects both verification and regression tests are important</a>, does it mean that the two should be separate? Like first, let's migrate the data, and then we'll rewrite the functionality, right? Or let's do it the other way around - we'll talk with the customer, incrementally figure out their requirements, deliver the software (with a proper regression test suite) that satisfies them, and then we migrate. Both approaches have problems:</p><br/><ul><br/><li>customers want to use the software with their current, real data - having only the data and no application to use it with is no value to them. Neither is having only an application with no data in it</li><br/><li>real data has lots of surprising scenarios that the domain expert might have forgotten to specify (see <em>caveats</em> though)</li><br/><li>requirements are not static, and new ones will be introduced during the development process, that inevitably will cause the new application's models to change, which means that <a href="http://blog.objectmentor.com/articles/2009/01/09/the-big-redesign-in-the-sky">the migration has a moving target it needs to migrate to</a>. </li><br/></ul><br/><h1>Doing them in parallel</h1><br/><p>If the data source is organized chronologically (<code>order by date</code> in the migration script), and organized in a format that resembles what the system's end users will enter into the system, then we can use the new application's outmost automatable entry point (Selenium, HTTP POST, a module's public API) to enter this data during the migration from the old system to the new.</p><br/><h2>Why</h2><br/><p>While a clear <em>disadvantage of this approach is speed of the migration</em> - it will be likely slower than an <code>INSERT INTO new_db.new_table select .... FROM old_db.old_table join ... where ....</code> statement, but in the case of non-trivial migrations it will likely compensate for the slowness, because:</p><br/><ul><br/><li>changes to the new system's code/data structure become a problem localized to the new application code - no headaches to update the migration scripts <em>in addition to the code</em></li><br/><li>when the client requests the demo deployment to be in sync with the old system, the code is ready (spare for the part to figure out which records have changed)</li><br/><li>the legacy data edge cases provides focus - no need to invent corner cases, for there will be enough in the data</li><br/><li>likely there will be releasable functionality sooner than with either of the above approaches</li><br/></ul><br/><h2>How</h2><br/><p>First, create the acceptance tests for the migration:</p><br/><ul><br/><li>Pick the data to be migrated</li><br/><li>find the view in the original system that displays this data to the users and find a way to extract the data from there</li><br/><li>define the equivalent view in the new system (it's about end to end, user visible features!)</li><br/><li>write the verification script that compares the above two (be sure to list the offending records in the failure message!)</li><br/><li>define the data entry point in the new system</li><br/><li>write the migration script - <em>extract</em> from the old system, <em>transform</em> if needed (only to match the entry points expectations of the format - no quality verification as in <a href="http://en.wikipedia.org/wiki/Extract%2C_transform%2C_load">classic ETL</a>!), then send it into the new system (using the above defined entry point)</li><br/></ul><br/><p>At this point both the new view, and the data entry points are empty. From here on, the <a href="http://pragprog.com/magazines/2011-11/testdriven-development">TDD</a> cycle becomes a nested loop</p><br/><ul><br/><li>run the migration script. See which record it failed for</li><br/><li>analyze the failing acceptance test, and find the missing features for it</li><br/><li><a href="http://gojko.net/FitNesse/book/">(A)TDD</a> the missing features</li><br/><li>run the migration script to restart the cycle</li><br/></ul><br/><h1>Caveats</h1><br/><p>While the existing data makes one focus on the real edge cases instead of the imagined one, beware - not everything has to (or can be) migrated - for instance, in a payment system, the system used to accept many currencies in the past, but now only <em>€</em>. IN this case, possibly the currency exchange handling logic could be dropped in the new system (and just to store the currency in a char field for the old ones); or in some other domains, maybe only the last ten years' data is needed. However, <em>this should be a business decision</em>, not a decision for a developer!</p><br/><p><em>Source Data Quality</em> is often a problem, one that will likely cause issues. If data needs to be fixed (as above, ask the stakeholders!), it should <em>stay out from your application's code</em>, and be in the <em>Transform</em> part of the migration script.</p>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2011/11/data-migrations-as-acceptance-tests.html">Data Migrations As Acceptance Tests</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>Testing Strategy On Migration Projects</title>
      <link>http://blog.zsoldosp.eu/2011/09/testing-strategy-on-migration-projects.html</link>
      <pubDate>Mon, 19 Sep 2011 17:30:00 CEST</pubDate>
      <category><![CDATA[software]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[legacy code]]></category>
      <category><![CDATA[rewrite]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2011/09/testing-strategy-on-migration-projects.html</guid>
      <description>Testing Strategy On Migration Projects</description>
      <content:encoded><![CDATA[
          
<p>It's common for migration projects (a.k.a.: rewrite) to specify scope initially as "to behave the same way as the old system does". Thus the testing approach to <em>automatically compare the new system's results to the old system's</em> seems to be a perfect choice (of course, in addition to the data migration, calculations should be reconciled too - at least for the records that were calculated using the latest version of the old system).</p><br/><p>However, once the application goes live and the old one is decommissioned, we cannot rely on these tests anymore (there is no old system anymore), and <em>we have no regression suite to rely on for the future change requests/enhancements</em>.</p><br/><p>Just to avoid any misunderstanding: I don't advocate not having automated reconciliation checks (verifications), on the contrary, I think they are immensely valuable. We can write the best specifications/code, but still miss some details, which, luckily for us, do pop up in the real data. These automated checks give everyone on the project team the peace of mind they so need before go-live. </p><br/><p>The point I'm trying to make here is that <em>while these checks are essential, they are not enough for the long term health of the system</em>. These are a good starting point, but just as we do with the specifications, as we work on the new system, when we find and uncovered logic case (e.g.: as part of the calculation reconciliation), we need to add a test case to the new application's test suite to ensure proper regression coverage that we can rely on in the years to come. And adding this test case is easy - we can just copypaste (after making it anonymous of course) the input that caused the problem with the verification into the unit/functional tests, implement the missing functionality, and move on. But saving on these few seconds costs a lot later down the road.</p><br/><p>Unit/functional/integration/system tests are supposed to be self contained - we would like to create (a) clean database(s), which we put into a known state before the tests (some frameworks support this out of the box, e.g.: Django, but we can easily implement this ourselves).  Migration reconciliations, by their very nature, need to work on the live (snapshot) data. Also, as described earlier, these reconciliation tests are temporary artifacts, while the other tests supposed to be permanent (at least until the client decides to change the requirements). Separation of Concerns also applies to the test suite - running tests in the same suite with different assumptions (live db we shouldn't touch vs. empty test db we can read/write as we wish) is more than risky - keep them physically separated, both at runtime and in source control.</p><br/><p>Even if the delivered project could be summed up in that vague sentence (does what the old does), this summary is never true - few start rewrite projects just to get the exact same functionality. Usually these projects are sponsored because the old application became unmaintainable and the client is missing opportunities, because the software is not supporting, but hindering their goals. Without the self-contained test suite, our shiny new migrated application is going to become another one of these.</p>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2011/09/testing-strategy-on-migration-projects.html">Testing Strategy On Migration Projects</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
  </channel>
</rss>
