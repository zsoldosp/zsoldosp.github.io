<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Do. Reflect. Learn. Repeat!</title>
    <link>http://zsoldosp.eu</link>
    <description>Excercises in public learning</description>
    <pubDate>Sat, 13 Jul 2013 15:33:37 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>Data Migrations As Acceptance Tests</title>
      <link>http://zsoldosp.eu/2011/11/data-migrations-as-acceptance-tests.html</link>
      <pubDate>Fri, 04 Nov 2011 09:23:00 CET</pubDate>
      <category><![CDATA[rewrite]]></category>
      <category><![CDATA[data migration]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[tdd]]></category>
      <category><![CDATA[software]]></category>
      <category><![CDATA[approach]]></category>
      <category><![CDATA[legacy code]]></category>
      <guid isPermaLink="false">http://zsoldosp.eu/2011/11/data-migrations-as-acceptance-tests.html</guid>
      <description>Data Migrations As Acceptance Tests</description>
      <content:encoded><![CDATA[
<p>While I have previously said that <a href="/2011/09/testing-strategy-on-migration-projects.html">on migration projects both verification and regression tests are important</a>, does it mean that the two should be separate? Like first, let's migrate the data, and then we'll rewrite the functionality, right? Or let's do it the other way around - we'll talk with the customer, incrementally figure out their requirements, deliver the software (with a proper regression test suite) that satisfies them, and then we migrate. Both approaches have problems:</p><br/><ul><br/><li>customers want to use the software with their current, real data - having only the data and no application to use it with is no value to them. Neither is having only an application with no data in it</li><br/><li>real data has lots of surprising scenarios that the domain expert might have forgotten to specify (see <em>caveats</em> though)</li><br/><li>requirements are not static, and new ones will be introduced during the development process, that inevitably will cause the new application's models to change, which means that <a href="http://blog.objectmentor.com/articles/2009/01/09/the-big-redesign-in-the-sky">the migration has a moving target it needs to migrate to</a>. </li><br/></ul><br/><h1>Doing them in parallel</h1><br/><p>If the data source is organized chronologically (<code>order by date</code> in the migration script), and organized in a format that resembles what the system's end users will enter into the system, then we can use the new application's outmost automatable entry point (Selenium, HTTP POST, a module's public API) to enter this data during the migration from the old system to the new.</p><br/><h2>Why</h2><br/><p>While a clear <em>disadvantage of this approach is speed of the migration</em> - it will be likely slower than an <code>INSERT INTO new_db.new_table select .... FROM old_db.old_table join ... where ....</code> statement, but in the case of non-trivial migrations it will likely compensate for the slowness, because:</p><br/><ul><br/><li>changes to the new system's code/data structure become a problem localized to the new application code - no headaches to update the migration scripts <em>in addition to the code</em></li><br/><li>when the client requests the demo deployment to be in sync with the old system, the code is ready (spare for the part to figure out which records have changed)</li><br/><li>the legacy data edge cases provides focus - no need to invent corner cases, for there will be enough in the data</li><br/><li>likely there will be releasable functionality sooner than with either of the above approaches</li><br/></ul><br/><h2>How</h2><br/><p>First, create the acceptance tests for the migration:</p><br/><ul><br/><li>Pick the data to be migrated</li><br/><li>find the view in the original system that displays this data to the users and find a way to extract the data from there</li><br/><li>define the equivalent view in the new system (it's about end to end, user visible features!)</li><br/><li>write the verification script that compares the above two (be sure to list the offending records in the failure message!)</li><br/><li>define the data entry point in the new system</li><br/><li>write the migration script - <em>extract</em> from the old system, <em>transform</em> if needed (only to match the entry points expectations of the format - no quality verification as in <a href="http://en.wikipedia.org/wiki/Extract%2C_transform%2C_load">classic ETL</a>!), then send it into the new system (using the above defined entry point)</li><br/></ul><br/><p>At this point both the new view, and the data entry points are empty. From here on, the <a href="http://pragprog.com/magazines/2011-11/testdriven-development">TDD</a> cycle becomes a nested loop</p><br/><ul><br/><li>run the migration script. See which record it failed for</li><br/><li>analyze the failing acceptance test, and find the missing features for it</li><br/><li><a href="http://gojko.net/FitNesse/book/">(A)TDD</a> the missing features</li><br/><li>run the migration script to restart the cycle</li><br/></ul><br/><h1>Caveats</h1><br/><p>While the existing data makes one focus on the real edge cases instead of the imagined one, beware - not everything has to (or can be) migrated - for instance, in a payment system, the system used to accept many currencies in the past, but now only <em>â‚¬</em>. IN this case, possibly the currency exchange handling logic could be dropped in the new system (and just to store the currency in a char field for the old ones); or in some other domains, maybe only the last ten years' data is needed. However, <em>this should be a business decision</em>, not a decision for a developer!</p><br/><p><em>Source Data Quality</em> is often a problem, one that will likely cause issues. If data needs to be fixed (as above, ask the stakeholders!), it should <em>stay out from your application's code</em>, and be in the <em>Transform</em> part of the migration script.</p>]]></content:encoded>
    </item>
    <item>
      <title>On Grassroots/Peer TDD Introduction</title>
      <link>http://zsoldosp.eu/2011/05/on-grassrootspeer-tdd-introduction.html</link>
      <pubDate>Sun, 15 May 2011 14:43:00 CEST</pubDate>
      <category><![CDATA[teaching]]></category>
      <category><![CDATA[software]]></category>
      <category><![CDATA[team]]></category>
      <category><![CDATA[change]]></category>
      <category><![CDATA[tdd]]></category>
      <guid isPermaLink="false">http://zsoldosp.eu/2011/05/on-grassrootspeer-tdd-introduction.html</guid>
      <description>On Grassroots/Peer TDD Introduction</description>
      <content:encoded><![CDATA[
<p>While I'm no trainer/coach, I've been involved in spreading TDD among my peers, with varying extent of success. Recently someone asked for advice on how they should go about it, and in the spirit of <a href="http://sethgodin.typepad.com">Seth Godin</a>, instead of responding in a private email, I wrote this post, a mix of experience and hindsight ideas.</p><br/> <p>So, we are one (or two) developers in the team/company, already sold on TDD, with some unit testing experience. The peers are willing to listen to the concept, and  management, while not willing to invest in formal training, is ok giving a chance, as long as it doesn't hurt the projects' performance. How do we go about it?</p><br/> <h2>Don't introduce TDD on the project</h2><br/> <p>It's common that teams learn/practice new skills on live projects after a basic overview/training. While this might work, I would not recommend this approach for any grassroots initiative, because the chances of failure are significant, and one bad experience with a practice/technology can doom any further attempts to introduce it later, even if not the practice was at fault, only was applied without enough practice. A project manager friend of mine recently complained to me that since the team that worked on a massive legacy project started doing TDD, tasks that used to take hours begun to take days, and clearly, he wasn't happy about that. It turned out that the problem wasn't due to TDD, but lack of discipline (developers went overboard with refactoring, touching parts of the codebase not even remotely connected to the task they've been working on). Despite this, he could have easily come to the conclusion that TDD equals to dropped productivity, without much benefit (bug reports kept coming in, even if for different features - we are talking about legacy code!). Any new skill has a learning curve, you will be slowed down, and you won't get it perfect the first time - don't give a chance for the others to associate failures with the new concept. If you are like me and would need a more concrete example about refactoring just enough, I suggest you read <a href="http://xprogramming.com/">Ron Jeffries</a>' <a href="http://www.amazon.com/Extreme-Programming-Adventures-DV-Microsoft-Professional/dp/0735619492">Extreme Programming Adventures in C#</a> book, and on advice for dealing with legacy code, the undisputed classic book is <a href="http://michaelfeathers.typepad.com/">Michael Feathers</a>' <a href="http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052">Working Effectively with Legacy Code</a>.</p><br/> <h2>Introducing/selling TDD to the other developers</h2><br/> <p>A lot of technical presentations focus on the <strong>how</strong> instead of <strong>why</strong> it is beneficial to the audience. When it comes to TDD, I would also suggest presenting it simple - skip the emerging design concept (some of the early advocates noted that good design emerging from TDD might had to do with the fact that those early advocates actually had great design sense anyway), don't mention YAGNI - in short, don't overload them with new concepts. I rather liked the approach <a href="http://www.paulbutcher.com/">Paul Butcher</a> took in his <a href="http://pragprog.com/titles/pbdp/debug-it">Debug It!</a> book - we tend to program one baby step at a time, articulating in our mind what the next behavior we'll implement should be, then we code it, and move to the next behavior. TDD (or Test First Development for the nitpickers :)) is just a minor step from that, i.e.: we actually write down the articulated concept in code (which we tend to do anyways with the throwaway main methods used for debugging). And in addition, we get an automated regression test suite for free :). While a live demo could be cool, I would probably show <a href="http://katas.softwarecraftsmanship.org/?p=71">one</a> of the <a href="http://www.katacasts.com/">Kata casts</a> instead of me typing on the projector. Also, be sure to point out that at first we won't be able to code at this speed (I still can't)!</p><br/> <h2>Learning/practice</h2><br/> <p>TDD is a rather simple concept, but so are all the great wisdoms - it takes a lot of time and experience to fully understand those concepts. After the initial TDD sales pitch, I would dedicate a session to going over the tools and the basic usage - how to install the test library, how to run the tests, how to debug a single test, and the basic assert statements - <a href="http://www.nunit.org/index.php?p=equalityAsserts&amp;r=2.5.10">AreEqual</a> vs. <a href="http://www.nunit.org/index.php?p=identityAsserts&amp;r=2.5.10">AreSame</a>, <a href="http://www.nunit.org/index.php?p=exceptionAsserts&amp;r=2.5.10">Assert.Throws</a>, and also an example to show that most likely there are more asserts in the library (e.g. <a href="http://www.nunit.org/index.php?p=stringAssert&amp;r=2.5.10">StringAssert.EndsWith</a>).</p><br/> <p>With those interested/committed, we can move on to the <strong>supervised practice</strong> step. We've worked on <a href="http://codingdojo.org/cgi-bin/wiki.pl?KataCatalogue">simple problems</a>, in a structure inspired by this <a href="http://www.infoq.com/presentations/Building-Good-Habits">Peer learning presentation</a> by <a href="http://www.codemanship.co.uk/">Jason Gorman</a> (his site even has a full <a href="http://www.codemanship.co.uk/sc_at_bbc.pdf">case study</a> of this applied at the BBC). The <a href="http://codingdojo.org/cgi-bin/wiki.pl?WhatIsCodingDojo">coding dojo</a> is another possible format. Important thing is discuss the experiences, lessons learnt, and problems overcome with the whole group, because while practice makes one perfect, bad, practiced habits are hard to unlearn. It is OK not to have all the answers - just be ready to admit it, and ensure that you can find it out from somewhere. Meetups, user groups, and similar forums are invaluably helpful.</p> <br/> <p>Be sure to eat elephant in a piecemeal fashion - while at first the simple problems seem contrived, don't attempt to practice testing existing, complex production code. Stick to the simple problems for practice, every now and then actually demonstrate that it is possibly to test legacy code (though it'll require quite some preparation from you), maybe have some of these examples as a group exercise, but be sure to keep the practice focused on the simple mechanics initially. Just like any sport practice - you repeat rather basic exercises over and over, because it does pay off in the long run, but to keep you motivated, you do have the free practice sessions too.</p><br/> <h2>Don't force it</h2><br/> <p>Not everyone has the same passion as you do (you must have if you read this far :)), and some take a longer time to learn, have different pre-existing concerns they should overcome. Lead by example, be available to talk about it, answer questions, clarify, but don't try to force it on them. Urban cycling didn't became popular because we, cyclists, were preaching to pedestrians and car drivers - we were just approachable to friends, coworkers, etc. and provided answers and listened to their concerns. Yes, it could take a long time, but patience pays off - self-motivated people are more likely to overcome the hurdles they inevitably will face in the learning process!</p><br/> <h2>Bringing it to production</h2><br/> <p>I wouldn't set strong rules or hard deadlines like "two months from now, you all must write all production code in a TDD fashion", but rather just tell people to feel free to experiment during their daily work, but ensure they don't confuse work and practice. If they get stuck on testing some problem, they should just make a note, and deliver the feature untested, as they used to do before. Later, together with the group they should discuss it and potentially find a way to test it.</p><br/> <h2>Further resources</h2><br/> <p>This post is just a high level overview, and I have simply glossed over many of the actual difficulties about writing good unit tests, keeping them maintainable, etc.. There are books written about the topic, in almost all programming languages. Coming from a .NET background, I can recommend <a href="http://www.amazon.com/Art-Unit-Testing-Examples-NET/dp/1933988274/">The Art of Unit Testing with examples in .NET</a> by <a href="http://osherove.com/">Roy Osherov</a>, and I've found <a href="http://jamesshore.com/">James Shore</a>'s <a href="http://jamesshore.com/Blog/Lets-Play/">Let's Play TDD</a> Java episodes great - the best thing about the latter is the thought process narrative that goes with it. <a href="http://pragprog.com/titles/trevan/driving-technical-change">Driving Technical Change</a> might be another good book, though I haven't yet read that.</p><br/> <p>Good luck!</p>
<hr><ol>
<li id="1">
    <strong><a href="http://www.blogger.com/profile/18146700402920753476">Miklos</strong></a> on <em>2011/05/16 19:10:12</em>: Thank you for your valuable advice PÃ©ter, it will be very useful for our TDD study group. I especially like that you answered in a blog post instead of an email, so other people can also benefit from your answer.
</li><li id="2">
    <strong><a href="/">Peter Zsoldos</strong></a> on <em>2011/05/16 19:55:11</em>: @Miklos: my pleasure :) Would  be fun to read about your experience (and lessons learned) in a couple of months!
</li></ol>
]]></content:encoded>
    </item>
  </channel>
</rss>
