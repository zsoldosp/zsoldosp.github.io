<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Do. Reflect. Learn. Repeat!</title>
    <link>http://blog.zsoldosp.eu</link>
    <description>Excercises in public learning</description>
    <pubDate>Fri, 01 Dec 2023 18:50:50 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>Teach me refactoring from my commits!</title>
      <link>http://blog.zsoldosp.eu/2013/09/27/teach-me-refactoring-from-my-commits/</link>
      <pubDate>Fri, 27 Sep 2013 09:40:00 CEST</pubDate>
      <category><![CDATA[things i wish existed]]></category>
      <category><![CDATA[version control]]></category>
      <category><![CDATA[refactoring]]></category>
      <category><![CDATA[untested ideas]]></category>
      <category><![CDATA[teaching]]></category>
      <guid isPermaLink="false">GZ4JOnYZvQe5D8VUfKUh6eJAlkw=</guid>
      <description>Teach me refactoring from my commits!</description>
      <content:encoded><![CDATA[
          <p>I find it hard to learn purely by abstract theory - I need practical 
examples to illustrate the theory I just learned. I also need practice,
and preferably, supervised practice, so my mistakes can be caught early
and/or more efficient ways can be shown to achieve the same thing I just
did.</p>
<p>With this background, it's not surprising that when I <a href="http://episodes.gitminutes.com/2013/06/gitminutes-14-pablo-santos-on.html">heard about a 
product that started to do semantic diffs for version 
control</a> I was reminded of the <a href="https://sc2010subs.wordpress.com/2010/08/13/refactoring-golf-dave-cleal-ivan-moore/">Refactoring 
Golf</a> concept from the first <a href="http://www.codemanship.co.uk/parlezuml/softwarecraftsmanship/">Software Craftsmanship 
London</a> conference - and the two ideas just clicked into this
great (ok, I'm biased) idea to try to derive the most efficient
refactoring steps for that particular commit I just made.</p>
<p>The pieces required for this project are all already in place:</p>
<ul>
<li>we have parsers for languages, and many are available as libraries to
  traverse <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">ASTs</a></li>
<li>most version control systems have libraries to read from them</li>
<li>there are tons of well-defined refactorings known, that can be used
  as operations in the transformations from state <code>A</code> to <code>B</code></li>
<li>optimization algorithms are plentiful - for a proof of concept, the
  <a href="https://en.wikipedia.org/wiki/String_distance">String Distance</a> Transformation algorithm could be used</li>
</ul>
<p>Thus such a program script could be added as a post commit hook, or 
simply could be run on the workspace copy, using the diff against last
committed version, and it could tell me that I might have:</p>
<ol>
<li>renamed variable <code>login</code> to <code>username</code></li>
<li>converted <code>username</code> from local variable to method parameter</li>
<li>extracted method <code>lock_customer_acocunt</code> from method <code>login</code></li>
</ol>
<p>I'm pretty positive even experienced refactoring practitioners could 
learn new tricks, and newbies would be delivered concrete refactoring
examples tailored to their very codebase.</p>
<p>Please, someone with enough free time, go and make such an app!</p>
<p>Does this idea make sense for you too, or just me? Let me know via email
(hello at site domain) or on twitter (<a href="https://twitter.com/zsepi">@zsepi</a>)!</p>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2013/09/27/teach-me-refactoring-from-my-commits/">Teach me refactoring from my commits!</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>Inversion of Control for Continuous Integration</title>
      <link>http://blog.zsoldosp.eu/2012/01/inversion-of-control-for-continuous.html</link>
      <pubDate>Fri, 17 Feb 2012 20:36:00 CET</pubDate>
      <category><![CDATA[version control]]></category>
      <category><![CDATA[software]]></category>
      <category><![CDATA[ioc]]></category>
      <category><![CDATA[continuous integration]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2012/01/inversion-of-control-for-continuous.html</guid>
      <description>Inversion of Control for Continuous Integration</description>
      <content:encoded><![CDATA[
          
<h1>Problem Description</h1><br/><br/><p>Our build structure is pretty stable, but the exact content of the steps varies as we discover more smoke tests that we'd like to add to, or when we rearrange the location of these checks.</p><br/><br/><p>The CI servers I've used made this a rather cumbersome process:</p><br/><br/><ul class="simple"><br/><br/><li>First, I have to leave my development environment to go to the build servers configuration of choice - most of the time it is a web interface, and for some it is a config file</li><br/><br/><li>I have to point and click, and if it's a shell script, I have to make my modifications without syntax highlighting (for the config files usually take the shell command to execute as a string, so no syntax highlighting)</li><br/><br/><li>If it's a web interface, I have (or had) no versioning/backup/diff support for my changes (config files are better in this aspect).</li><br/><br/><li>If it's a config file, then I need to get it to the build server (we version control our config files), so that's at least one more command</li><br/><br/><li>I need to save my changes, and run a whole build to see whether my changes worked, which is a rather costly thing.</li><br/><br/><li>Most places have only one build server, so when I'm changing the step, I either edit the real job (bad idea) or make a copy of it, edit it, and then integrate it back to the real job. Of course, integrating back means: copy and paste.</li><br/><br/><li>If the build failed, I need to go back to the point and click and no syntax highlighting step to fix the failures</li><br/><br/><li>Last, but not least, with web interfaces, concurrent modifications of a build step lead to nasty surprises!</li><br/><br/></ul><br/><br/><br/><br/><h1>Normal development workflow</h1><br/><br/><ul class="simple"><br/><br/><li>I have an idea what I want to do</li><br/><br/><li>I write the tests and code to make it happen</li><br/><br/><li>I run the relevant tests and repeat until it's working</li><br/><br/><li>I check for source control updates</li><br/><br/><li>I run the pre-commit test suite (for dvcs people: pre-push)</li><br/><br/><li>Once all tests pass I commit, and move on to the next problem</li><br/><br/></ul><br/><br/><p>Quite a contrast, isn't it? And even the concurrent editing problem is solved!</p><br/><br/><br/><h1>Quick'n'Dirty Inversion of Control for builds</h1><br/><br/><p>Disclaimer: the solution described below is a really basic, low tech, proof of concept implementation.</p><br/><br/><p>Since most build servers at the end of the day</p><br/><br/><ul class="simple"><br/><br/><li>invoke a shell command</li><br/><br/><li>and interpret exit codes, <tt class="docutils literal">stdout</tt>, <tt class="docutils literal">stderr</tt>, and/or log files</li><br/><br/></ul><br/><br/><p>we defined the basic steps (update from version control, initialize database, run tests, run checks, generate documentation, notify) using the standard build server configuration, but the non-built in steps (all, except the version control update and the notification) are defined to invoke a shell script that resides in the project's own repository (e.g.: under bin/ci/oncommit/runchecks.sh). These shell scripts' results can be interpreted by the standard ways CI servers are familiar with - exceptions and stack traces, (unit)test output, and exit codes.</p><br/><br/><br/><h1>Benefits</h1><br/><br/><ul class="simple"><br/><br/><li>adding an extra smoke test doesn't require me to break my flow, and I can more easily test my changes locally and integrating it back into the main build means just committing it to the repository, and the next build will already pick this up</li><br/><br/><li>I can run the same checks locally if I would like to</li><br/><br/><li>if I were to support a bigger team/organization with their builds, this would make it rather easy to maintain a standard build across teams, yet allow each of them to customize their builds as they see it fit</li><br/><br/><li>if I were to evaluate a new build server product, I could easily and automatically see how it would work under production load, just by:<ul><br/><br/><li>creating a single parameterized build (checkout directory, source code repository)</li><br/><br/><li>defining the schedule for each build I have</li><br/><br/><li>and then replaying the past few weeks/months load - OK, I still would need to write the script that would queue the builds for the replay, but it still is more effective than to run the product only with a small pilot group and then see it crash under production load</li><br/><br/></ul><br/><br/></li><br/><br/></ul><br/><br/><br/><h1>Shortcomings, Possible Improvements</h1><br/><br/><p>As said, the above is a basic implementation, but has served a successful proof of concept for us. However, our builds are simple:</p><br/><br/><ul class="simple"><br/><br/><li>no dependencies between the build steps, it is simply chronological</li><br/><br/><li>no inter-project dependencies, such as component build hierarchy (if the server component is built successfully, rerun the UI component's integration tests in case the server's API changed, etc.)</li><br/><br/><li>the tests are executed in a single thread and process, on a single machine - no parallelization or sharding</li><br/><br/></ul><br/><br/><p>All of the above shortcomings could be addressed by writing a build server specific interpreter that would read our declarative build config file (map steps to scripts, define step/build dependencies/workflows), and would redefine the build's definition on the server. By creating a standard build definition format, we could just as easily move our builds between different servers as we can currently do with blogs - pity Google is not a player in the CI space, so the <a class="reference external" href="http://www.dataliberation.org/">Data Liberation Front</a> cannot help :).</p><br/><br/><br/><h1>Questions</h1><br/><br/><p>Does this idea make sense for you? Does such a solution already exist? Or are the required building blocks available? Let me know in the comments!</p>
<hr><ol>
<li id="1">
    <strong><a href="http://www.blogger.com/profile/06859781419645954688">bridge</strong></a> on <em>2012/02/21 14:55:14</em>: What we do at our build server is something similar to this:<br/><br/>We have ant steps defined, e.g. build, run checkstyle, run unit tests. We have different Hudson jobs for the same branch, one for each purpose.<br/><br/>Applying this environment for your scenario (tell me if I missed something from the problem) would look like this:<br/>- we could create a new job for the integration tests.<br/>- for changing the integration tests, we could write new tests and add them to the corresponding ant step. We could write the code and the ant xml in our favorite IDE. We could run them in our environment before committing it.<br/>- we can use the output of the build step in the same way we usually do. This is right now stop/go; but I think there are other ways to do this out there.
<ol>
<li id="1-1">
    <strong><a href="/">Peter Zsoldos</strong></a> on <em>2012/02/21 19:41:11</em>: Yup, your example achieves the same purpose as what I described. I have used the shell script in this example because a) I haven't worked on java projects in ages and I forgot it exists b) we have a number of scripts (both shell and django runscripts/management commands as well) that we reuse <br/><br/>When you say multiple jobs, you mean for one project (branch) you have 4-5 jobs or one job with multiple parallel steps?
</li></ol></li><li id="2">
    <strong><a href="http://www.blogger.com/profile/06859781419645954688">bridge</strong></a> on <em>2012/02/22 13:55:01</em>: When I say multiple jobs, we have 2 jobs for each branch. I don't know if we can make Hudson smarter - this is how the experts set it up initially, and nobody ever questioned it.<br/><br/>Having predefined scripts, as placeholders to invoke other scripts - that is poor-mans-ant: you have a layer of abstraction between the CI server and the scripts that are actually running. Say for instance, Hudson invokes the smoketest.sh, which invokes the low-level step, something like this:<br/><br/>#!/bin/bash<br/>compile.sh<br/>dist.sh<br/>run-unit-tests.sh<br/>check-login-ui.sh<br/>check-the-crazy-rollback-use-case.sh<br/><br/>So all you had to do would be add a new line to this shell/perl file.<br/><br/>Or, in perl (or python, whatever) you can add any other logic<br/>#!/usr/bin/perl<br/>if (system("dist.sh") != 0) {<br/>  exit;<br/>}<br/>if (system("run-unit-tests.sh") != 0) {<br/>  exit;<br/>}<br/>#...<br/><br/>Here you can add alternative and parallel flows too. A bit ugly, programmatic, but works. Even more, you can keep it clean if you keep the actual step's scripts and the flow's scripts in different files.<br/><br/>SoapUI is not a CI solution, but still, it's something similar as it's a testing tool. They suggest to use scripts in order to define custom logic between the test steps. http://www.soapui.org/Functional-Testing/controlling-flow.html
</li></ol>

          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2012/01/inversion-of-control-for-continuous.html">Inversion of Control for Continuous Integration</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
  </channel>
</rss>
