<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Do. Reflect. Learn. Repeat!</title>
    <link>http://blog.zsoldosp.eu</link>
    <description>Excercises in public learning</description>
    <pubDate>Mon, 01 Feb 2016 10:54:13 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>A few thoughts on BDDon't</title>
      <link>http://blog.zsoldosp.eu/2015/12/09/a-few-thoughts-on-bddon-t/</link>
      <pubDate>Wed, 09 Dec 2015 23:00:00 CET</pubDate>
      <category><![CDATA[bdd]]></category>
      <category><![CDATA[python]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[behave]]></category>
      <category><![CDATA[cucumber]]></category>
      <category><![CDATA[gherkin]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">i_P3Vr2QhglZzxeTvlHSfb_4o6w=</guid>
      <description>A few thoughts on BDDon't</description>
      <content:encoded><![CDATA[
          <p><strong>Note</strong>: apparently I wrote this blog post, but forgot to publish it
back in december. I will publish it nonetheless together with the 
<a href="/2016/02/01/warnings-warn-some-deprecationwarning-gotchas/">python warnings</a> post, and keep the publish/create date the 
original from last year.</p>
<hr />
<p>Kevin Dishman wrote an article titled <a href="https://www.thoughtworks.com/p2magazine/issue12/bdd-dont/">BDDon't</a>, in which he
raises a few objections against issues common with the tools and common
practices of them. As recently at the <a href="https://www.softwerkskammer.org/">Softwerkskammer</a> Nuremberg
user group we've just talked about Gherkin style testing after my 
<a href="https://github.com/zsoldosp/polytesting-taskboard">polytesting talk</a>, I'm now doubly prompted to blog some
thoughts.</p>
<div class="toc">
<ul>
<li><a href="#contextdisclaimer">Context/Disclaimer</a></li>
<li><a href="#i-agree-with-kevins-problem-statements">I agree with Kevin's problem statements</a></li>
<li><a href="#despite-that-i-still-like-gherkin-tools">Despite that, I still like Gherkin tools</a><ul>
<li><a href="#it-forces-separation-of-test-test-glue-and-app-code">It forces separation of test, test glue, and app code</a></li>
<li><a href="#gherkin-docs-can-be-useful-beyond-dev">Gherkin docs can be useful beyond dev</a></li>
<li><a href="#dont-have-to-test-things-on-the-full-stack-level">Don't have to test things on the full stack level</a></li>
</ul>
</li>
<li><a href="#reduce-the-pain-for-gherkin">Reduce the pain for Gherkin</a><ul>
<li><a href="#regular-expression-mapping-parameter-variance">Regular-expression mapping - Parameter variance</a><ul>
<li><a href="#different-abstraction-levels">Different abstraction levels</a></li>
<li><a href="#relying-on-the-applications-own-defaults">Relying on the application's own defaults</a></li>
<li><a href="#using-step-tables-beware-this-is-defaults-in-disguise">Using step tables (beware, this is defaults in disguise!)</a></li>
</ul>
</li>
<li><a href="#global-state">Global state</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="contextdisclaimer">Context/Disclaimer</h2>
<ul>
<li>I've only used <a href="https://github.com/behave/behave">behave</a>, so it's entirely possible it has
  different behavior from the tool implementation(s) Kevin used</li>
<li>I don't run the behave tests on the selenium level</li>
<li>I have never worked for an airline, though flew enough times already.
  But to be consistent with Kevin's examples, I will use this domain to
  illustrate points</li>
<li>I don't exclusively use only BDD tests</li>
</ul>
<h2 id="i-agree-with-kevins-problem-statements">I agree with Kevin's problem statements</h2>
<ul>
<li>Regular-expression mapping can become complex and error prone
  and should be avoided</li>
<li>Global state and step interdependencies are also error prone
  and should be avoided</li>
<li>
<blockquote>
<p>If the business is really interested in participating in test
specification, this would be a great opportunity for them to
pair with someone familiar and comfortable with the test suites the
team has created.</p>
</blockquote>
</li>
</ul>
<h2 id="despite-that-i-still-like-gherkin-tools">Despite that, I still like Gherkin tools</h2>
<h3 id="it-forces-separation-of-test-test-glue-and-app-code">It forces separation of test, test glue, and app code</h3>
<p>Writing readable tests are hard. While on a team with a great culture
and strong discipline this isn't a challenge, on teams that are not yet
experts in testing I find this constraint really helpful.</p>
<h3 id="gherkin-docs-can-be-useful-beyond-dev">Gherkin docs can be useful beyond dev</h3>
<p>As stated above, I've found that motivated stakeholders, BAs, etc. will
be fine reading Java, Ruby, Python test code. However, other people can
find value from an existing - and filterable/navigable (!) - Gherkin
documents, e.g.: tech/customer support people could appreciate
<a href="/2010/08/executable-documentation.html">living documents</a>. A new support person would need the same
info as a new developer making changes in that area! Or imagine if your
processes need to be audited - persuading an auditor to read natural
text might be easier than getting them to navigate codebases.</p>
<h3 id="dont-have-to-test-things-on-the-full-stack-level">Don't have to test things on the full stack level</h3>
<p>Even if Gherkin is used for acceptance testing, some
algorithms/calculations can be tested on the unit/component level, never
even touching the UI to provide the confidence the developers (business)
need(s). As time goes on, it's even possible to transition tests up and
down the test pyramid (thanks to <a href="https://twitter.com/clepce">Stefan Clepce</a> for bringing
<a href="http://pythonhosted.org/behave/new_and_noteworthy_v1.2.5.html#test-stages">behave stages</a> to my attention)!</p>
<h2 id="reduce-the-pain-for-gherkin">Reduce the pain for Gherkin</h2>
<h3 id="regular-expression-mapping-parameter-variance">Regular-expression mapping - Parameter variance</h3>
<h4 id="different-abstraction-levels">Different abstraction levels</h4>
<p>The problem of complex test data isn't unique to BDD tools - integrated
tests written in any tool will face the same problem. And the solutions
are similar - in the tests where I care about the concrete values, I
specify all the test values explicitly, and in tests where I don't care
about those details and operate at a higher level abstraction, I create
sample (random) data for that - a'la <a href="http://pytest.org/latest/fixture.html">pytest fixtures</a></p>
<p>E.g.: instead of </p>
<p><code>Given I have booked 2 flights</code></p>
<p>I might say</p>
<pre><code>Given I booked a valid flight
And I booked another valid flight
</code></pre>

<p>both these steps can match to the same step implementation - whether via
regex, multiple methods calling the same actual implementation, or via
some other way. Here I quite like <a href="https://github.com/behave/behave">behave</a>'s annotations, i.e.:
I can say </p>
<pre><code>@given('I booked a valid flight')
@given('I booked another valid flight')
def booked_a_valid_flight(context):
    ....
</code></pre>

<p>Or I might even test things in isolation, not even sharing step
implementations - I might test that the OLTP model gets translated 
to the correct reporting model, and for the report I only test things
on the report data model (see step tables below).</p>
<h4 id="relying-on-the-applications-own-defaults">Relying on the application's own defaults</h4>
<p>I have never booked a flight for an unaccompanied minor. Until reading
Kevin's article, it hasn't even occurred to me that is a use case to
consider, yet I've booked quite a number of flights.</p>
<p>I'm sure there is an option to specify that. However, that option by
default is not check in the application for the checkout - the customer
explicitly has to request it to be able to specify such a scenario.</p>
<p>Thus for such a scenario, I likely would include an explicit step for
booking with an unaccompanied minor.</p>
<h4 id="using-step-tables-beware-this-is-defaults-in-disguise">Using step tables (beware, this is defaults in disguise!)</h4>
<p><a href="https://github.com/behave/behave">Behave</a> supports <a href="http://pythonhosted.org/behave/gherkin.html#table">step table data</a></p>
<pre><code>Given I have booked a flight
   | type                     | return |
   | with unaccompanied minor | true   |
</code></pre>

<p><em>technically, the above would need a header, but in the step implementation,
the header could be treated as the first row, if that aids readability.</em></p>
<p>This can cause more complex test code, but if each step corresponds to
an actual action in the application (a'la <a href="https://pragprog.com/magazines/2010-08/page-objects-in-python">Page Object</a>), then
there should be no extra logic in the step handler - each line here
corresponds to a form input (or HTTP POST) entry.</p>
<h3 id="global-state">Global state</h3>
<p>In <a href="https://github.com/behave/behave">behave</a>, each step implementation method receives a
<a href="https://github.com/behave/behave/blob/11757e7/behave/runner.py#L33">Context</a> object to store its state (changes) in,</p>
<blockquote>
<p>This object is a place to store information related to the tests you're
running. You may add arbitrary attributes to it of whatever value you need.</p>
<p>During the running of your tests the object will have additional layers of
namespace added and removed automatically. There is a "root" namespace and
additional namespaces for features and scenarios.</p>
</blockquote>
<p>This is unlike it is implemented e.g.: in <a href="https://cucumber.io/docs/reference/jvm#java">cucumber-jvm</a>, and
maybe that's why I haven't run into this issue (though external global
state, such as a database can still be shared).</p>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2015/12/09/a-few-thoughts-on-bddon-t/">A few thoughts on BDDon't</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>Unit Testing In Elixir</title>
      <link>http://blog.zsoldosp.eu/2014/03/05/unit-testing-in-elixir/</link>
      <pubDate>Wed, 05 Mar 2014 19:30:00 CET</pubDate>
      <category><![CDATA[elixir]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[programming languages]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">0o-82cbUaxJeza1AWri2hAjNJqg=</guid>
      <description>Unit Testing In Elixir</description>
      <content:encoded><![CDATA[
          <div class="document">
<p><em>Note that all of this was written at the time of Elixir
0.12.5-dev, so things might have changed since.</em></p>
<p>Since the <a class="reference external" href="http://elixir-lang.org/getting_started/ex_unit/1.html">tutorial</a>
covers the mechanics pretty well, this post is more about my
impressions of Elixir's approach to this topic.</p>
<div class="section" id="built-in">
<h1>Built-in</h1>
<p>Unit testing is built into the language and the tools, as well as the
tutorial - I love this approach. When you create a new project with
<tt class="docutils literal">mix</tt>, this is the output you get:</p>
<pre class="code bash literal-block">
<span class="nv">$ </span>mix new myproject
...
Your mix project was created successfully.
You can use mix to compile it, <span class="nb">test </span>it, and more:

    <span class="nb">cd </span>myproject
    mix compile
    mix <span class="nb">test

</span>Run <span class="sb">`</span>mix <span class="nb">help</span><span class="sb">`</span> <span class="k">for </span>more information.
</pre>
</div>
<div class="section" id="the-test-skeleton-is-not-beginner-friendly">
<h1>The test skeleton is not beginner friendly</h1>
<p>The skeleton unit test suffers the same problems like the <a class="reference external" href="http://djangoproject.com">Django</a>
equivalent - it is aimed at those who get unit testing already. If you
are new to automated testing, seeing code like</p>
<pre class="code elixir literal-block">
<span class="k">defmodule</span> <span class="no">FooTest</span> <span class="k">do
  </span><span class="kn">use</span> <span class="no">ExUnit</span><span class="o">.</span><span class="no">Case</span>

  <span class="n">test</span> <span class="s2">&quot;the truth&quot;</span> <span class="k">do
    </span><span class="n">assert</span><span class="p">(</span><span class="no">true</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</pre>
<p>won't really make you say <em>&quot;yes, this makes me understand and love testing!&quot;</em>.
Granted, the whole Elixir tutorial is aimed at people who can already
program.</p>
</div>
<div class="section" id="simplified-yet-flexible-assertions">
<h1>Simplified, yet flexible assertions</h1>
<p>Unlike classic unit testing frameworks, which come bundled with
numerous <tt class="docutils literal">assertWhatever</tt> and <tt class="docutils literal">assertNotWhatever</tt> etc. methods,
(various overloads for each type), ExUnit mostly only uses <tt class="docutils literal">assert</tt> and
<tt class="docutils literal">assert_raise</tt> (though there are some more - see
<a class="reference external" href="http://elixir-lang.org/docs/stable/ExUnit.Assertions.html">ExUnit.Assertions</a>).
Rather, it relies on pattern matching and the assert macro being
smart enough to figure out how to provide a good (enough) failure
message - in this aspect, it reminds me of <a class="reference external" href="http://pytest.org/latest/">py.test</a></p>
<p>I'm curious to see whether it will stay this way - custom assertions
are superb for writing DSL-like code that experts can read (e.g.:
<a class="reference external" href="http://hamcrest.org/">Hamcrest</a>), and I really like the protocol-based extensibility
model used in Elixir elsewhere.</p>
</div>
<div class="section" id="constraint-of-the-failure-messages">
<h1>Constraint of the failure messages</h1>
<p>Your opinion of this feature might differ from mine, but it's worth
pointing this out. While the assertions are pretty flexible,
the actual error message will become the <strong>values</strong> on the left- and right
hand side of the pattern matching. This takes away the information of
exactly which method was called with what parameters, which
I have grown to rely on in Python. Consider the following tests and
the resulting failure messages - which one is more helpful?</p>
<p><a class="reference external" href="/snippets/unit_testing_with_elixir_gofl.exs">Elixir</a>:</p>
<pre class="code elixir literal-block">
    <span class="n">test</span> <span class="s2">&quot;survival - a living cell with 2 or 3 neighbours survives&quot;</span> <span class="k">do
        </span><span class="n">assert</span> <span class="no">Gofl</span><span class="o">.</span><span class="no">Rules</span><span class="o">.</span><span class="n">next_state</span><span class="p">(</span><span class="ss">:alive</span><span class="p">,</span> <span class="m">2</span><span class="p">)</span> <span class="o">==</span> <span class="ss">:alive</span>
        <span class="n">assert</span> <span class="no">Gofl</span><span class="o">.</span><span class="no">Rules</span><span class="o">.</span><span class="n">next_state</span><span class="p">(</span><span class="ss">:alive</span><span class="p">,</span> <span class="m">3</span><span class="p">)</span> <span class="o">==</span> <span class="ss">:alive</span>
        <span class="n">assert</span> <span class="no">Gofl</span><span class="o">.</span><span class="no">Rules</span><span class="o">.</span><span class="n">next_state</span><span class="p">(</span><span class="ss">:dead</span><span class="p">,</span> <span class="m">3</span><span class="p">)</span> <span class="o">==</span> <span class="ss">:alive</span>
        <span class="n">assert</span> <span class="no">Gofl</span><span class="o">.</span><span class="no">Rules</span><span class="o">.</span><span class="n">next_state</span><span class="p">(</span><span class="ss">:dead</span><span class="p">,</span> <span class="m">2</span><span class="p">)</span> <span class="o">==</span> <span class="ss">:dead</span>
    <span class="k">end</span>
</pre>
<pre class="code bash literal-block">
  1<span class="o">)</span> <span class="nb">test </span>survival - a living cell with 2 or 3 neighbours survives <span class="o">(</span>GoflRulesTest<span class="o">)</span>
     ** <span class="o">(</span>ExUnit.ExpectationError<span class="o">)</span>
                  expected: :alive
       to be equal to <span class="o">(==)</span>: :dead
     at unit_testing_with_elixir_gofl.exs:18



Finished in 0.05 seconds <span class="o">(</span>0.04s on load, 0.01s on tests<span class="o">)</span>
1 tests, 1 failures
</pre>
<p><a class="reference external" href="/snippets/unit_testing_with_elixir_gofl.py">Python</a>:</p>
<pre class="code python literal-block">
    <span class="k">def</span> <span class="nf">test_survival_a_living_cell_with_2_or_3_neighbours_survives</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="n">ALIVE</span><span class="p">,</span> <span class="n">cell_next_state</span><span class="p">(</span><span class="n">curr_state</span><span class="o">=</span><span class="n">ALIVE</span><span class="p">,</span> <span class="n">live_neighbour_cnt</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="n">ALIVE</span><span class="p">,</span> <span class="n">cell_next_state</span><span class="p">(</span><span class="n">curr_state</span><span class="o">=</span><span class="n">ALIVE</span><span class="p">,</span> <span class="n">live_neighbour_cnt</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="n">ALIVE</span><span class="p">,</span> <span class="n">cell_next_state</span><span class="p">(</span><span class="n">curr_state</span><span class="o">=</span><span class="n">DEAD</span><span class="p">,</span> <span class="n">live_neighbour_cnt</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="n">DEAD</span><span class="p">,</span> <span class="n">cell_next_state</span><span class="p">(</span><span class="n">curr_state</span><span class="o">=</span><span class="n">DEAD</span><span class="p">,</span> <span class="n">live_neighbour_cnt</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre>
<pre class="code bash literal-block">
<span class="nv">F</span>
<span class="o">======================================================================</span>
FAIL: test_survival_a_living_cell_with_2_or_3_neighbours_survives <span class="o">(</span>__main__.GoflRulesTest<span class="o">)</span>
----------------------------------------------------------------------
Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
  File <span class="s2">&quot;unit_testing_with_elixir_gofl.py&quot;</span>, line 22, in test_survival_a_living_cell_with_2_or_3_neighbours_survives
    self.assertEquals<span class="o">(</span>DEAD, cell_next_state<span class="o">(</span><span class="nv">curr_state</span><span class="o">=</span>DEAD, <span class="nv">live_neighbour_cnt</span><span class="o">=</span>2<span class="o">))</span>
AssertionError: False !<span class="o">=</span> True

----------------------------------------------------------------------
Ran 1 <span class="nb">test </span>in 0.000s

FAILED <span class="o">(</span><span class="nv">failures</span><span class="o">=</span>1<span class="o">)</span>
</pre>
<p>Granted, Python is unique in this regard, IIRC I wouldn't get such
useful stacktraces in C# or Java either, but since I've been mostly
working in Python lately, it certainly was a surprise - not necessarily
for discouraging multiple assertions per test (it's a valid approach),
but more the hiding of the call site information.</p>
<p>However, since <tt class="docutils literal">assert</tt> itself is a macro, its technically possible
to change the assertion - added to my list of things to try :)</p>
</div>
<div class="section" id="async">
<h1>:async</h1>
<p>Test isolation is almost always hard, and these issues tend to only come
out from hiding once tests need to run in parallel for speed - good things
never come alone :) So having concurrent test running built in from the
start is a great way to have the one big (future) problem broken into
many minor inconveniences.</p>
<p>I also like that instead of a test runner command line switch, it is
declared on the TestCase level whether it's OK to run it in parallel
- giving finer control to the test author.</p>
<pre class="code elixir literal-block">
<span class="k">defmodule</span> <span class="no">GoflRulesTest</span> <span class="k">do
    </span><span class="kn">use</span> <span class="no">ExUnit</span><span class="o">.</span><span class="no">Case</span><span class="p">,</span> <span class="ss">async:</span> <span class="no">true</span>
</pre>
<p>I just wish it was true by default!</p>
</div>
<div class="section" id="cool-things-i-would-like-to-explore-further">
<h1>Cool things I would like to explore further</h1>
<ol class="arabic">
<li><dl class="first docutils">
<dt>This short exploration hasn't allowed me figure what kind of</dt>
<dd><p class="first last"><strong>differences</strong> there are <strong>between</strong> testing <strong>functional</strong>-
and <strong>object oriented</strong> programs. My gut feeling is there
shouldn't be many: black box, transformation (state) based should
be the same. Interaction testing (mocking) seems an odd fit, however
it might just turn out to be as easy as passing in a &quot;mock&quot; function
as an argument.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>Property-based testing</strong> has been on my radar for a while to be</dt>
<dd><p class="first last">tried - and its use seems to be more common in functional programming,
and it's appropriate I should try it in a context where it's set up
to succeed. This is when I'm thankful for Elixir being
built/run on top of a mature platform - otherwise there wouldn't yet
be an available library.</p>
</dd>
</dl>
</li>
</ol>
</div>
</div>

          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2014/03/05/unit-testing-in-elixir/">Unit Testing In Elixir</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>End-to-End Testing - A Code Example</title>
      <link>http://blog.zsoldosp.eu/2014/02/15/end-to-end-testing-a-code-example/</link>
      <pubDate>Sat, 15 Feb 2014 17:15:00 CET</pubDate>
      <category><![CDATA[django]]></category>
      <category><![CDATA[end-to-end]]></category>
      <category><![CDATA[code]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">VQdt1K4VFfD0lxpX8wRk-1HuUSE=</guid>
      <description>End-to-End Testing - A Code Example</description>
      <content:encoded><![CDATA[
          <div class="document">
<dl class="docutils">
<dt>Prior posts in <a class="reference external" href="/category/end-to-end/">this series</a>:</dt>
<dd><ul class="first last simple">
<li><a class="reference external" href="/2013/10/23/a-new-look-at-end-to-end-testing-polymorphic-and-fast/">A New Look At End-to-End Testing - Polymorphic and Fast</a></li>
<li><a class="reference external" href="/2013/10/28/going-beyond-regression-what-other-benefits-could-end-to-end-testing-provide/">Going Beyond Regression - What Other Benefits could End-to-End Testing Provide?</a></li>
</ul>
</dd>
</dl>
<p>Abstract concepts are always easier to learn with concrete examples.
This is the first code-heavy post in the series, and it is intended to
illustrate the mechanics of the concept, not yet how it is applied to
the problem domain. For this reason, I use the example of <a class="reference external" href="https://en.wikipedia.org/wiki/Fibonacci_number">Fibonacci
Numbers</a>, with a naive
implementation - the business logic is not the emphasis here, but how we
test them on multiple levels.</p>
<p>I chose <a class="reference external" href="https://www.djangoproject.com/">Django</a> to write the code,
in because of its lovely built in end-to-end testing support, but
knowing that not everyone is a Django developer (yet!), I chose <em>not</em>
to use any of the more idiomatic <a class="reference external" href="https://docs.djangoproject.com/en/1.6/topics/class-based-views/">Django class based views</a>,
since the purpose of this post is not to teach idiomatic Django.</p>
<p>Enough of the disclaimers, on to the code!</p>
<div class="section" id="the-specs-for-the-app">
<h1>The Specs for the App</h1>
<pre class="code python literal-block">
<span class="k">class</span> <span class="nc">FibonacciCalculatorTests</span><span class="p">:</span>

    <span class="k">def</span> <span class="nf">test_cannot_calculate_sequence_elements_less_than_one</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assert_cannot_calculate</span><span class="p">(</span><span class="n">n</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assert_cannot_calculate</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assert_can_calculate</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_currently_we_cannot_calculate_numbers_greater_than_10</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assert_can_calculate</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assert_cannot_calculate</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assert_cannot_calculate</span><span class="p">(</span><span class="mi">7895</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_can_calculate_the_first_ten_fibonacci_numbers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="mi">6</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="mi">7</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="mi">21</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="mi">34</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="mi">9</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="mi">55</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">test_can_only_calculate_fibonacci_for_integers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assert_cannot_calculate</span><span class="p">(</span><span class="mf">3.14</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assert_cannot_calculate</span><span class="p">(</span><span class="s">'not a number'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assert_cannot_calculate</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">assert_can_calculate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertIsNotNone</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre>
<p>We'll get to the implementation of <strong>assert_cannot_calculate</strong> next.</p>
</div>
<div class="section" id="the-business-logic">
<h1>The Business Logic</h1>
<p>Let's add the actual test implementation</p>
<pre class="code python literal-block">
<span class="kn">from</span> <span class="nn">django.test</span> <span class="kn">import</span> <span class="n">TestCase</span>
<span class="kn">from</span> <span class="nn">simple_fibonacci</span> <span class="kn">import</span> <span class="n">calculator</span><span class="p">,</span> <span class="n">urls</span>


<span class="k">class</span> <span class="nc">InMemory</span><span class="p">(</span><span class="n">FibonacciCalculatorTests</span><span class="p">,</span> <span class="n">TestCase</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">assert_cannot_calculate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_fibonacci</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">calculator</span><span class="o">.</span><span class="n">fibonacci</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre>
<p>Followed by the calculator fibonacci logic</p>
<pre class="code python literal-block">
<span class="k">def</span> <span class="nf">fibonacci</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c"># don't do this in production</span>
    <span class="c"># use https://en.wikipedia.org/wiki/Fibonacci_number#Closed-form_expression</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">'value (</span><span class="si">%r</span><span class="s">) too low'</span> <span class="o">%</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">'value (</span><span class="si">%r</span><span class="s">) too high'</span> <span class="o">%</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">fibonacci</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">fibonacci</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="this-is-a-webservice-let-s-test-the-json-api">
<h1>This is a webservice, let's test the JSON API!</h1>
<p>You can probably guess, this is where we add the second implementation
for the FibonacciCaulcatorTests:</p>
<pre class="code python literal-block">
<span class="kn">import</span> <span class="nn">simple_fibonacci</span>
<span class="kn">from</span> <span class="nn">django.test.client</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="kn">from</span> <span class="nn">django.core.urlresolvers</span> <span class="kn">import</span> <span class="n">reverse</span>
<span class="kn">import</span> <span class="nn">json</span>


<span class="k">class</span> <span class="nc">JsonHttpResponse</span><span class="p">(</span><span class="n">FibonacciCalculatorTests</span><span class="p">,</span> <span class="n">TestCase</span><span class="p">):</span>

    <span class="n">urls</span> <span class="o">=</span> <span class="n">simple_fibonacci</span><span class="o">.</span><span class="n">urls</span>

    <span class="k">def</span> <span class="nf">assert_cannot_calculate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci_parsed_json_response</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="s">'result'</span> <span class="ow">in</span> <span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="s">'ERROR'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'status'</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">get_fibonacci</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci_parsed_json_response</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="s">'error'</span> <span class="ow">in</span> <span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="s">'OK'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'status'</span><span class="p">],</span> <span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="s">'result'</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_fibonacci_parsed_json_response</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">()</span>
        <span class="n">url</span> <span class="o">=</span> <span class="n">reverse</span><span class="p">(</span><span class="s">'fibonacci'</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="p">{</span><span class="s">'n'</span><span class="p">:</span> <span class="n">n</span><span class="p">},</span> <span class="n">HTTP_ACCEPT</span><span class="o">=</span><span class="s">'application/json'</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
        <span class="n">allowed_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="s">'status'</span><span class="p">,</span> <span class="s">'n'</span><span class="p">,</span> <span class="s">'error'</span><span class="p">,</span> <span class="s">'result'</span><span class="p">])</span>
        <span class="n">data_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="nb">set</span><span class="p">([]),</span> <span class="n">data_keys</span> <span class="o">-</span> <span class="n">allowed_keys</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="nb">unicode</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">data</span><span class="p">[</span><span class="s">'n'</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">data</span>
</pre>
<p>As you can see, on top of the assertions in the base class, I've added
a few additional assertions, for the api contract (invariants) - this
api shouldn't return extra fields, or if it does, I should be notified
and then decided whether that's a bug that needs correction or a feature,
in which case I'll adjust the <strong>allowed_keys</strong> variable</p>
<p>And here is the implementation:</p>
<pre class="code python literal-block">
<span class="kn">from</span> <span class="nn">django.views.generic</span> <span class="kn">import</span> <span class="n">View</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">django.http</span> <span class="kn">import</span> <span class="n">HttpResponse</span>
<span class="kn">from</span> <span class="nn">simple_fibonacci</span> <span class="kn">import</span> <span class="n">calculator</span>


<span class="k">class</span> <span class="nc">FibonacciView</span><span class="p">(</span><span class="n">View</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">post</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">request</span><span class="p">):</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">POST</span><span class="p">[</span><span class="s">'n'</span><span class="p">]</span>
        <span class="n">error</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">calculator</span><span class="o">.</span><span class="n">fibonacci</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">error</span> <span class="o">=</span> <span class="nb">unicode</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="n">content</span><span class="p">,</span> <span class="n">content_type</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">get_response_content_and_type_function</span><span class="p">(</span><span class="n">request</span><span class="p">)(</span>
                <span class="n">n</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">result</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_response</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">content_type</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_response_content_and_type_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">request</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">json_response</span>

    <span class="k">def</span> <span class="nf">json_response</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">result</span><span class="p">):</span>
        <span class="n">response_data</span> <span class="o">=</span> <span class="p">{</span><span class="s">'n'</span><span class="p">:</span> <span class="n">n</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">error</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">response_data</span><span class="p">[</span><span class="s">'status'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'ERROR'</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">response_data</span><span class="p">[</span><span class="s">'status'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'OK'</span>
            <span class="n">response_data</span><span class="p">[</span><span class="s">'result'</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response_data</span><span class="p">),</span> <span class="s">'application/json'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_response</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">content_type</span><span class="p">):</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">HttpResponse</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
        <span class="n">response</span><span class="p">[</span><span class="s">'Content-Type'</span><span class="p">]</span> <span class="o">=</span> <span class="n">content_type</span>
        <span class="k">return</span> <span class="n">response</span>
</pre>
</div>
<div class="section" id="let-s-expose-this-feature-to-normal-user-as-html">
<h1>Let's expose this feature to normal user as HTML!</h1>
<p>The order of the events is sometimes the other way around, but sooner
or later the point comes when the same functionality must be exposed
through a different channel - whether it's a simplified/more efficient
power user interface for your internal support people as opposed to
your first time customers through the public web shop, or adding a
mobile app for your web service, it will happen. And it's nice to know
we can execute the same set of tests against all implementations.</p>
<p>Let's update the tests first:</p>
<pre class="code python literal-block">
<span class="kn">import</span> <span class="nn">re</span>


<span class="k">class</span> <span class="nc">HtmlUserFriendlyHttpResponse</span><span class="p">(</span><span class="n">FibonacciCalculatorTests</span><span class="p">,</span> <span class="n">TestCase</span><span class="p">):</span>

    <span class="n">urls</span> <span class="o">=</span> <span class="n">urls</span>

    <span class="k">def</span> <span class="nf">assert_cannot_calculate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci_response</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertContains</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">'&lt;p class=&quot;error&quot;&gt;'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertNotContains</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">'&lt;p class=&quot;success&quot;&gt;'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_fibonacci</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fibonacci_response</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertContains</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">'&lt;p class=&quot;success&quot;&gt;'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertNotContains</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">'&lt;p class=&quot;error&quot;&gt;'</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span>
            <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
                <span class="s">r'&lt;span id=&quot;result&quot;&gt;(\d+)&lt;/span&gt;'</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">content</span>
            <span class="p">)</span> <span class="o">.</span><span class="n">groups</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">get_fibonacci_response</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">()</span>
        <span class="n">url</span> <span class="o">=</span> <span class="n">reverse</span><span class="p">(</span><span class="s">'fibonacci'</span><span class="p">)</span>
        <span class="n">client</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">HTTP_ACCEPT</span><span class="o">=</span><span class="s">'text/html'</span><span class="p">)</span>  <span class="c"># as the user, we first load the page</span>
        <span class="n">post_response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="n">url</span><span class="p">,</span> <span class="p">{</span><span class="s">'n'</span><span class="p">:</span> <span class="n">n</span><span class="p">},</span> <span class="n">HTTP_ACCEPT</span><span class="o">=</span><span class="s">'text/html'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEquals</span><span class="p">(</span><span class="s">'text/html'</span><span class="p">,</span> <span class="n">post_response</span><span class="p">[</span><span class="s">'Content-Type'</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">post_response</span>
</pre>
<p>And update our implementation:</p>
<pre class="code python literal-block">
<span class="kn">from</span> <span class="nn">django.views.generic</span> <span class="kn">import</span> <span class="n">View</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">django.http</span> <span class="kn">import</span> <span class="n">HttpResponse</span>
<span class="kn">from</span> <span class="nn">simple_fibonacci</span> <span class="kn">import</span> <span class="n">calculator</span>


<span class="k">class</span> <span class="nc">FibonacciView</span><span class="p">(</span><span class="n">View</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">post</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">request</span><span class="p">):</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">POST</span><span class="p">[</span><span class="s">'n'</span><span class="p">]</span>
        <span class="n">error</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">calculator</span><span class="o">.</span><span class="n">fibonacci</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">error</span> <span class="o">=</span> <span class="nb">unicode</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="n">content</span><span class="p">,</span> <span class="n">content_type</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">get_response_content_and_type_function</span><span class="p">(</span><span class="n">request</span><span class="p">)(</span>
                <span class="n">n</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">result</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_response</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">content_type</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_response_content_and_type_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">request</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">json_response</span>

    <span class="k">def</span> <span class="nf">json_response</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">result</span><span class="p">):</span>
        <span class="n">response_data</span> <span class="o">=</span> <span class="p">{</span><span class="s">'n'</span><span class="p">:</span> <span class="n">n</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">error</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">response_data</span><span class="p">[</span><span class="s">'status'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'ERROR'</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">response_data</span><span class="p">[</span><span class="s">'status'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'OK'</span>
            <span class="n">response_data</span><span class="p">[</span><span class="s">'result'</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response_data</span><span class="p">),</span> <span class="s">'application/json'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_response</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">content_type</span><span class="p">):</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">HttpResponse</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
        <span class="n">response</span><span class="p">[</span><span class="s">'Content-Type'</span><span class="p">]</span> <span class="o">=</span> <span class="n">content_type</span>
        <span class="k">return</span> <span class="n">response</span>
</pre>
<hr class="docutils" />
<p>That's the concept. The <a class="reference external" href="/category/end-to-end/">series</a> will
continue with me developing an app, and sharing relevant snippets
and lessons learned from that project. Stay tuned!</p>
</div>
</div>

          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2014/02/15/end-to-end-testing-a-code-example/">End-to-End Testing - A Code Example</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>Going Beyond Regression - What Other Benefits could End-to-End Testing Provide?</title>
      <link>http://blog.zsoldosp.eu/2013/10/28/going-beyond-regression-what-other-benefits-could-end-to-end-testing-provide/</link>
      <pubDate>Mon, 28 Oct 2013 08:05:00 CET</pubDate>
      <category><![CDATA[untested ideas]]></category>
      <category><![CDATA[code]]></category>
      <category><![CDATA[business analysis]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[end-to-end]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">1ojU7m2klQVoaVtPAyBIp7nHdds=</guid>
      <description>Going Beyond Regression - What Other Benefits could End-to-End Testing Provide?</description>
      <content:encoded><![CDATA[
          <p>In last week's post, I gave a few examples about when <a href="/2013/10/23/a-new-look-at-end-to-end-testing-polymorphic-and-fast/">Polymorphic
End-to-End Testing</a> testing makes sense. In this post, I would
like to take a step back and list a few additional benefits that could
be derived from end to end testing in general, regardless of the fashion
they were written in.</p>
<p><em>Note: some of these points can also apply to non-end-to-end tests too,
that were written in a black box style with proper test abstractions. 
While it could be argued that then the system is that one component, I
would rather just focus on the benefits we can derive on top of the 
regression / specification of the system.</em></p>
<p><em>Disclaimer:</em> note this post has been filed under <a href="/category/untested-ideas/">untested ideas</a>
 - they sound good, but I haven't gotten around to implementing all of
them.</p>
<h2 id="big-refactorings-and-rewrites">Big Refactorings and Rewrites</h2>
<p>Change is inevitable, and they often violate previous assumptions. 
Sometimes whole components (or systems) have to be rewritten. Having a 
set of tests that operate on a much higher abstraction level (e.g.: HTTP
GET/POST requests) can provide the required safety net to avoid 
regressions and making sure all relevant scenarios are addressed.</p>
<p>Some changes where this Page (Application) Object abstraction has helped
us:</p>
<ul>
<li>when converting a single page checkout process to a multi-step 
    wizard style checkout</li>
<li>when the article numbers used in our system changed</li>
<li>when we had to synchronize data into a new system - we could just 
    expand our assertions in the end-to-end tests to make sure that 
    every known scenario is written correctly into the new system</li>
</ul>
<p><a href="http://blog.8thlight.com/uncle-bob/2013/09/23/Test-first.html">It's easy to reconstruct a system from its tests, but much harder to do
it the other way around</a>. It has been
great to only adjust a few driver API methods and get the same amount of
functional coverage as before, without having to rewrite the test suite.</p>
<h2 id="forces-the-team-to-think-about-the-user-interface-and-experience">Forces the team to think about the user interface (and experience)</h2>
<p>While it is not required, it often made us reduce the complexity in 
the UI - when we find that a certain step is being exercised by a 
method with a single parameter from the tests, yet that method then 
derives a bunch of additional parameters to POST against the page, it
suggests one of two things: </p>
<ol>
<li>we are missing some test cases for these extra parameters</li>
<li>maybe we don't need these parameters to be provided by the end user,
    but we could derive them in the application too.</li>
</ol>
<p>Often the helper methods created can expose the need for additional 
support interfaces that won't probably come up during the specifications
phase, only after go-live.<br />
</p>
<p>Last, but not least, end-to-end gives us tests for the UI, yet the tests
remain maintainable - usually a single test API method is all that needs
to be fixed after template changes (and designers are even harder to get
to write tests than developers :)). <a href="http://ayende.com/blog/160929/on-failing-tests">Don't be afraid of many test 
failures!</a></p>
<h2 id="correlate-tests-with-other-business-metrics">Correlate tests with other business metrics</h2>
<p>While I recall people suggesting we run applications with a <a href="https://en.wikipedia.org/wiki/Code_coverage">coverage 
profiler attached</a>, the performance penalty is usually 
prohibiting.</p>
<p>However, I haven't yet seen a web application without a ton of external
metrics related to the urls in the app. If our tests are written against
urls too, after some data munging (primary keys and actual form values
surely won't match test values exactly, but translating them to <code>GET to 
view 1</code>, <code>POST to view 2</code>) we can correlate our tests with these 
metrics. </p>
<p>Some such metrics:</p>
<ul>
<li>application (webserver) access logs</li>
<li>Google Analytics or equivalent</li>
<li>...</li>
</ul>
<p>What can we learn from these correlations/comparisons?</p>
<ul>
<li>are we concentrating our tests in the least visited areas?</li>
<li>are we testing what our users are doing? Sure, it's nice that in our
    tests people sequentially finish their checkout, without wondering
    off the known path, but is this how they behave in production?</li>
</ul>
<h2 id="testcase-similarity-analysis">TestCase similarity analysis</h2>
<p>Some test scenarios will come up in multiple aspects of the system. 
Placing an order will trigger a bunch of actions in other modules - 
fulfillment, customer profile updates, marketing classification, invoice
rendering, notification emails, etc.</p>
<p>Sometimes these features are added with big time gaps in between, maybe
even the team members have changed over time. The ability to compare 
the requests the different TestCases make, and say that these two 
(three, four, etc.) TestCases seem to execute the same kind of requests
up to a point as the TestCase being added, but they also have the 
following extra paths they all execute, but the new TestCase doesn't...
Causing the developer to realize - of course, there are special rules
for orders from educational institutions!</p>
<h2 id="reducing-the-gap-between-end-user-error-reports-and-tests">Reducing the gap between end user error reports and tests</h2>
<p>Probably this is the least unexpected idea in the list, but worth 
stating nonetheless.</p>
<h2 id="in-place-help-for-trusted-users">In place help (for trusted users)</h2>
<p>Sure, this might require careful considerations, but giving the users 
the ability to browse the test cases/methods that matches their workflow
up to the current page, in a searchable fashion (if I place an order 
like this now, when will the X email be sent) could greatly reduce 
support work for the developer team. <em>Note: the purpose of this is not 
to isolate the developers from the users!!!</em></p>
<h2 id="always-up-to-date-screenshots-and-videos">Always up-to-date screenshots and videos</h2>
<p>Those manuals that have screenshots from many releases ago... Adding (or
marking) some test cases to be linked against documentation sections, and
having the tests actually take screenshots about them or record them as 
video sounds like a pretty useful idea for me. One could go further, 
such as highlighting the values/input fields where the test sends 
input, and the parts of the page that are asserted against...</p>
<p>And if the support team has access to the same API, they could even 
create these screenshots/videos for the customer as they are answering
their question (Here, take a look at this video, this is how the thing
you asked for is done).</p>
<hr />
<p>There must be many more ideas out there - let me know about them, and 
I'm happy to add them to this list (or link to wherever you published
it)!</p>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2013/10/28/going-beyond-regression-what-other-benefits-could-end-to-end-testing-provide/">Going Beyond Regression - What Other Benefits could End-to-End Testing Provide?</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>A New Look At End-to-End Testing - Polymorphic and Fast</title>
      <link>http://blog.zsoldosp.eu/2013/10/23/a-new-look-at-end-to-end-testing-polymorphic-and-fast/</link>
      <pubDate>Wed, 23 Oct 2013 19:28:00 CEST</pubDate>
      <category><![CDATA[untested ideas]]></category>
      <category><![CDATA[end-to-end]]></category>
      <category><![CDATA[code]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">ity9bCalQkCuoSztWSPkSrQ8XGs=</guid>
      <description>A New Look At End-to-End Testing - Polymorphic and Fast</description>
      <content:encoded><![CDATA[
          <p>At the end of this post, there is a list of reasons why to work with 
end-to-end tests, but first please consider the post's idea on its own.
After that, I'm glad to have discussions about alternative/better 
solutions to the described (or omitted) contexts.</p>
<p>Please, read it first ;)</p>
<h1 id="terms-used">Terms used</h1>
<p>The below points are not intended to be full blown definitions, but
rather pointers.</p>
<ul>
<li>End-to-End testing - as <a href="http://gojko.net/2010/03/31/tdd-with-complex-infrastructures/">Nat Pryce has said in one of his 
    presentations</a>, the ends are always farther apart than one 
    thinks they are. The purpose is to execute the tests through as much
    of the application stack as possible - from the front end at least
    till the storage mechanism.</li>
<li>Polymorphism - I use it here mostly in the way demonstrated by the 
    <a href="https://en.wikipedia.org/wiki/Liskov_Substitution_Principle">Liskov Substitution Principle</a> - code written against an abstraction
    should be unaffected regardless of the concrete implementation of 
    that abstraction is given to it.</li>
</ul>
<h1 id="polymorphic-tests-we-are-already-doing-it">Polymorphic tests - we are already doing it</h1>
<p>Some of us already run the same tests on top of different code - we can
have multiple build platforms (x86 and x64, Windows and Linux, Python 2 
and 3, etc.), multiple configurations (SQLite and PostgreSQL), as well
as multiple versions of our dependent libraries (stable, latest release, 
and latest). What's common though among these scenarios is that the 
polymorphism happens largely <em>outside</em> of our codebase, and we don't 
have to think much about it when writing tests. </p>
<p>An example of executing multiple drivers <em>inside</em> our code is the use of 
Selenium tests - the same tests are run against Chrome, Firefox, etc. 
While each of the drivers is testing on the same level (Web UI), the 
actual browser drivers have different implementations, exposed via a 
common abstraction level - DOM selectors and event invocations.</p>
<p>Of course, most test code uses some level of abstraction to separate
the test logic from the actual page implementations.</p>
<h1 id="abstractions-page-objects">Abstractions - Page objects</h1>
<p>The <a href="http://martinfowler.com/bliki/PageObject.html">Page Object</a> pattern is used to help creating maintainable tests.
Instead of writing tests coupled to the implementations (go to this 
concrete url, wait <code>N</code> seconds for it to load, find and select the form
elements for username and password, etc.), these implementation details 
are hidden behind well named methods (e.g.: <code>open_login_form</code>, 
<code>login_with_credentials</code>, etc.), and thus are domain (client) friendly
and readable. And Page Objects can be composed together to build 
Application Objects.</p>
<p>Similar abstraction is used by the various Acceptance Testing tools,
such as FitNesse, Cucumber, and the other Gherkin tools - the spec texts
contain terms and values important for the business domain, and there
is separate code translating the spec's values and terms to call into 
the application and transforming its state into a format
expected by the tool.</p>
<h1 id="stripped-down-tests-only-the-script">Stripped down tests - only the script</h1>
<p>As seen above, the AT tools separate application logic from the test 
scenario's description.</p>
<p>Assertions have also been separated from test cases - either by developer 
choice, choosing to use a separate Assertions library like Hamcrest, 
instead of the unit testing library's own <code>assertFoo</code> methods), or
explicitly (<a href="http://visionmedia.github.io/mocha/#assertions">Mocha ships without an assertions library</a>).</p>
<p>Thus tests can really be focused just on the scenario being tested.</p>
<h1 id="fast-tests">Fast tests</h1>
<p>The single biggest disadvantage of <a href="http://www.confreaks.com/videos/641-gogaruco2011-fast-rails-tests">end to end tests is their speed</a>. They are slow. And the more of them there are, the slower they are.</p>
<p>This is one reason why the <a href="http://martinfowler.com/bliki/TestPyramid.html">Test Pyramid</a> recommends not having 
too many of them. Many architectural approaches (<a href="http://alistair.cockburn.us/Hexagonal+architecture">hexagonal</a>, DDD, etc.) 
suggest keeping a lightweight core application, and to attach the 
persistence and UI layers to it at its boundaries, leaving these ports 
and adapters lightweight too. Most of the testing then happens against
the core, dependency independent code, making the tests fast. </p>
<h1 id="fast-end-to-end-tests">Fast end to end tests</h1>
<p>Drumroll... we'll do a bit of cheating, of course. </p>
<p>Not all the tests have to run every single time. Performance tests are
usually not done when TDDing - that kicks in either later in 
the deployment pipeline, or runs daily. Teams organize their tests into
fast, smoke, and slow suites. Locally (and as the first step in the build
process) only the fast and smoke tests are run.</p>
<p>Putting all the above together means that writing systems with two 
self- contained cores (the app domain itself and the test scenarios) 
easily lends itself to end-to-end testing that can be run on multiple 
configurations, to give confidence that the app works with all its 
components and dependencies in production - yet enable fast feedback
required for developers. The same tests can be run:</p>
<ul>
<li>directly against the core application with mocks, stubs, etc.</li>
<li>through the app's (http) UI via the given frameworks/libraries testing 
  tools (e.g.: <code>django.test.client.Client</code>) with an in-memory database</li>
<li>through selenium against the full stack</li>
</ul>
<p>And of course, we can mix and match - selenium against SQLite, etc.</p>
<p>While TDDing, one can run the tests only against the fast core, after
that is complete, we can run the relevant tests with the end-to-end
driver, fix any mistakes that occur, check in, and let the build server
run all the integrated tests (using existing build practices to 
achieve speed)!</p>
<h2 id="in-which-contexts-could-it-make-sense">In Which Contexts Could It Make Sense?</h2>
<p>Thank you for reading this far - assuming you didn't just scroll 
ahead :)</p>
<p>The below list is by no means exhaustive, and as mentioned in the
introduction, there might be alternative approaches (please, let me
know!) - it's not a coincidence this blog is called "Exercises in 
public learning"! </p>
<p>With that out of the way, here are some contexts where this approach
could make sense:</p>
<ul>
<li>
<p>Working with a team where the skills both for testing and for writing
    good code are (yet) missing (<a href="http://5whys.com/blog/the-3-maturity-stages-of-a-software-team-and-how-scrum-fails.html">Chaotic team phase</a>).</p>
<p>As the joke goes, the only way to eat the elephant is one bite at a 
time. Same goes for learning - people can be overwhelmed to make 
the mental jump from manual to automated testing - throwing in good
programming practices can be too much.</p>
<p>Getting started with end to end tests that have decoupled driver
methods (even if on the <code>TestCase</code> class itself) is a great start - by
the time the tests become slow, if the team is bought into the idea
of automated testing, it can be refactored towards a core domain -
and inside that domain there still doesn't have to be proper clean
code (one step at a time).</p>
<p>In brief: for slow, gradual improvement.</p>
</li>
<li>
<p>The app actually has multiple interfaces for the same thing.</p>
<p>It can be due to A/B testing, or simply to accommodate the different
needs of different users (e.g.: for a webshop - there is the public
shop, the internal UI geared at the company's sales people, and the
API), multi-platform application (e.g.: mobile and desktop web, iOS and 
Android), etc.</p>
<p>If you test the checkout process end-to-end, then running the same
set of tests against each UI makes sense too - a single set of tests
to maintain and you know immediately whether all features work 
across all the views.</p>
</li>
<li>
<p>Catching unexpected bugs.</p>
<p>There is a class of bugs that can be caught by rigor, but I do slip
occasionally, ending up in a place where the unit tests are all 
green, but the application itself doesn't actually work.</p>
<p>Some real life such bugs I have run into:</p>
<ul>
<li>forgetting to place the actual input element on the page</li>
<li>encoding-persistence issues - an utf-8 database with a column
    that is windows-1250 encoded is ... unexpected</li>
<li>synchronizing data with another database where after the 
    required mappings it turned out said other database truncates
    our data</li>
</ul>
<p>All of the above can be addressed retroactively via adding targeted
tests for that specific integration point, but if we are already
testing the corner cases (length, encoding, etc.) in our code, it is 
nicer not to have to learn about these "unknown unknowns" from 
production problems...</p>
</li>
<li>
<p>Finally some related posts from other people:</p>
<ul>
<li>Ayende has multiple posts: on <a href="http://ayende.com/blog/154273/limit-your-abstractions-and-how-do-you-handle-testing">swapping out the infrastructure</a>, <a href="http://ayende.com/blog/4218/scenario-driven-tests">separating assertions from tests</a>, and <a href="http://ayende.com/blog/4217/even-tests-has-got-to-justify-themselves">about which tests add value in his opinion</a></li>
<li><a href="http://codebetter.com/sebastienlambla/2013/07/11/unit-testing-is-out-vertical-slice-testing-is-in/">Sebastien Lambla on Vertical Testing</a></li>
</ul>
</li>
</ul>
<p>There is much more to be said about other <a href="/2013/10/28/going-beyond-regression-what-other-benefits-could-end-to-end-testing-provide/">benefits of end to end 
testing</a>, but this post is already too long, so that will have to wait
for <a href="/2013/10/28/going-beyond-regression-what-other-benefits-could-end-to-end-testing-provide/">another post</a> (while waiting, you can read <a href="http://codemanship.co.uk/parlezuml/blog/?postid=1183">Jason Gorman's 101 Uses for Polymorphic testing</a>)!</p>
<p>P.S.: I would like to thank (in (first name based) alphabetical order): 
<a href="https://twitter.com/ajmolenaar">Arjan Molenaar</a>,
<a href="https://twitter.com/sietstweets">Cirilo Wortel</a>,
<a href="http://douglassquirrel.com/">Douglas Squirrel</a>,
<a href="http://twitter.com/jtf">Jeffrey Frederick</a>,
<a href="https://twitter.com/KishenPanday">Kishen Simbhoedatpanday</a>,
<a href="http://twitter.com/marcoemrich">Marco Emrich</a>,
<a href="https://twitter.com/mfeathers">Michael Feathers</a>,
and of course my colleagues at <a href="http://www.paessler.com">Paessler AG</a> -  I much appreciate that you 
all listened to me while I tried to figure out how to explain this and 
gave feedback both about the content and the format (*). Thank you!</p>
<hr />
<p>(*) just to be crystal clear, this does not mean they endorsed it, 
just that they listened and gave feedback!</p>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2013/10/23/a-new-look-at-end-to-end-testing-polymorphic-and-fast/">A New Look At End-to-End Testing - Polymorphic and Fast</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>Find The Test Structure That Fits Your Team</title>
      <link>http://blog.zsoldosp.eu/2012/01/find-test-structure-that-fits-your-team.html</link>
      <pubDate>Thu, 12 Jan 2012 19:14:00 CET</pubDate>
      <category><![CDATA[documentation]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2012/01/find-test-structure-that-fits-your-team.html</guid>
      <description>Find The Test Structure That Fits Your Team</description>
      <content:encoded><![CDATA[
          
<p>A number of recent posts by <a href="http://haacked.com/archive/2012/01/02/structuring-unit-tests.aspx">Phil Haack</a>, <a href="http://ayende.com/blog/152897/structuring-your-unit-tests-why">Ayende Rahien</a>, and <a href="http://www.typemock.com/blog/2012/01/11/do-tests-get-too-much-respect/">Gil Zilberfeld</a> dealt with the topic of test organization. Each approach has its pros and cons, but neither is a silver bullet. Your (and your team's, project's) context determines which approach is right.</p><br/><p>Without aiming to provide an exhaustive list, below are some questions that have influence on test organization:</p><br/><ul><br/><li>Is the team in a consulting project where test documentation is required as part of delivery? </li><br/><li>Is it a product team? Is the firm in its early stage or is it mature like Oracle with mature products?</li><br/><li>What is the turnover rate of the team? What are the plans for its growth? The team might have all the knowledge in their head, but if it'll double in size in a year, then the communication value of tests could increase.</li><br/><li>What is the maturity level of the team? How long have they been working together?</li><br/><li>How closely and often do team members collaborate? </li><br/><li>Is there <a href="http://www.extremeprogramming.org/rules/collective.html">collective code ownership</a>?</li><br/><li>How does the team and its customers communicate? Some customers can - and willing to - read code, some need English (Turkish/Hungarian/German/etc.). Some teams have a level of (grown and deserved) trust that just saying the software works is accepted, some need a more formal acceptance and regression process.</li><br/><li>Is there proper IDE support for discoverability? Do all people reporting bugs (as tests) have access to that IDE? If not so, how do they find examples of how to write the bug-report test?</li><br/></ul><br/><p>Feel free to add more questions in the comments!</p>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2012/01/find-test-structure-that-fits-your-team.html">Find The Test Structure That Fits Your Team</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>Data Migrations As Acceptance Tests</title>
      <link>http://blog.zsoldosp.eu/2011/11/data-migrations-as-acceptance-tests.html</link>
      <pubDate>Fri, 04 Nov 2011 09:23:00 CET</pubDate>
      <category><![CDATA[rewrite]]></category>
      <category><![CDATA[data migration]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[tdd]]></category>
      <category><![CDATA[software]]></category>
      <category><![CDATA[approach]]></category>
      <category><![CDATA[legacy code]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2011/11/data-migrations-as-acceptance-tests.html</guid>
      <description>Data Migrations As Acceptance Tests</description>
      <content:encoded><![CDATA[
          
<p>While I have previously said that <a href="/2011/09/testing-strategy-on-migration-projects.html">on migration projects both verification and regression tests are important</a>, does it mean that the two should be separate? Like first, let's migrate the data, and then we'll rewrite the functionality, right? Or let's do it the other way around - we'll talk with the customer, incrementally figure out their requirements, deliver the software (with a proper regression test suite) that satisfies them, and then we migrate. Both approaches have problems:</p><br/><ul><br/><li>customers want to use the software with their current, real data - having only the data and no application to use it with is no value to them. Neither is having only an application with no data in it</li><br/><li>real data has lots of surprising scenarios that the domain expert might have forgotten to specify (see <em>caveats</em> though)</li><br/><li>requirements are not static, and new ones will be introduced during the development process, that inevitably will cause the new application's models to change, which means that <a href="http://blog.objectmentor.com/articles/2009/01/09/the-big-redesign-in-the-sky">the migration has a moving target it needs to migrate to</a>. </li><br/></ul><br/><h1>Doing them in parallel</h1><br/><p>If the data source is organized chronologically (<code>order by date</code> in the migration script), and organized in a format that resembles what the system's end users will enter into the system, then we can use the new application's outmost automatable entry point (Selenium, HTTP POST, a module's public API) to enter this data during the migration from the old system to the new.</p><br/><h2>Why</h2><br/><p>While a clear <em>disadvantage of this approach is speed of the migration</em> - it will be likely slower than an <code>INSERT INTO new_db.new_table select .... FROM old_db.old_table join ... where ....</code> statement, but in the case of non-trivial migrations it will likely compensate for the slowness, because:</p><br/><ul><br/><li>changes to the new system's code/data structure become a problem localized to the new application code - no headaches to update the migration scripts <em>in addition to the code</em></li><br/><li>when the client requests the demo deployment to be in sync with the old system, the code is ready (spare for the part to figure out which records have changed)</li><br/><li>the legacy data edge cases provides focus - no need to invent corner cases, for there will be enough in the data</li><br/><li>likely there will be releasable functionality sooner than with either of the above approaches</li><br/></ul><br/><h2>How</h2><br/><p>First, create the acceptance tests for the migration:</p><br/><ul><br/><li>Pick the data to be migrated</li><br/><li>find the view in the original system that displays this data to the users and find a way to extract the data from there</li><br/><li>define the equivalent view in the new system (it's about end to end, user visible features!)</li><br/><li>write the verification script that compares the above two (be sure to list the offending records in the failure message!)</li><br/><li>define the data entry point in the new system</li><br/><li>write the migration script - <em>extract</em> from the old system, <em>transform</em> if needed (only to match the entry points expectations of the format - no quality verification as in <a href="http://en.wikipedia.org/wiki/Extract%2C_transform%2C_load">classic ETL</a>!), then send it into the new system (using the above defined entry point)</li><br/></ul><br/><p>At this point both the new view, and the data entry points are empty. From here on, the <a href="http://pragprog.com/magazines/2011-11/testdriven-development">TDD</a> cycle becomes a nested loop</p><br/><ul><br/><li>run the migration script. See which record it failed for</li><br/><li>analyze the failing acceptance test, and find the missing features for it</li><br/><li><a href="http://gojko.net/FitNesse/book/">(A)TDD</a> the missing features</li><br/><li>run the migration script to restart the cycle</li><br/></ul><br/><h1>Caveats</h1><br/><p>While the existing data makes one focus on the real edge cases instead of the imagined one, beware - not everything has to (or can be) migrated - for instance, in a payment system, the system used to accept many currencies in the past, but now only <em>€</em>. IN this case, possibly the currency exchange handling logic could be dropped in the new system (and just to store the currency in a char field for the old ones); or in some other domains, maybe only the last ten years' data is needed. However, <em>this should be a business decision</em>, not a decision for a developer!</p><br/><p><em>Source Data Quality</em> is often a problem, one that will likely cause issues. If data needs to be fixed (as above, ask the stakeholders!), it should <em>stay out from your application's code</em>, and be in the <em>Transform</em> part of the migration script.</p>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2011/11/data-migrations-as-acceptance-tests.html">Data Migrations As Acceptance Tests</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>Book Review - Python Testing Cookbook by Greg L. Turnquist</title>
      <link>http://blog.zsoldosp.eu/2011/10/book-review-python-testing-cookbook-by.html</link>
      <pubDate>Sun, 23 Oct 2011 13:24:00 CEST</pubDate>
      <category><![CDATA[python]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[book review]]></category>
      <category><![CDATA[software]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2011/10/book-review-python-testing-cookbook-by.html</guid>
      <description>Book Review - Python Testing Cookbook by Greg L. Turnquist</description>
      <content:encoded><![CDATA[
          
<p>I have been doing (developer) automated testing for years now, but I recently moved from <a href="http://www.microsoft.com/net/">.NET</a> to <a href="http://www.python.org/">Python</a>. Recently, at one point I suggested to collegues that we try <a href="http://concordion.org/">Concordion</a>, only to learn that there is the <a href="http://docs.python.org/library/doctest.html"><code>doctest module</code></a> that could be used to achieve similar result (more about that in a later post). Remembering my own advice: <a href="/2010/12/when-in-rome-do-as-romans-do.html">When In Rome, Do as the Romans Do</a>, I set out looking for a Python specific book about testing - and the <a href="http://www.packtpub.com/python-testing-cookbook/book">Python Testing Cookbook</a> by <a href="http://pythontestingcookbook.posterous.com/">Greg L. Turnquist</a> book seemed to be a good fit <a href="http://streamhacker.com/2011/07/18/python-testing-cookbook-review/">based on reviews</a>.</p><br/><hr/><br/><p>Overall, I liked the book, and it lived up to my expectations - it provided me with a list of tools and some sample code to get started with each of them. </p><br/><p>Beware that it is an entry level book - if, like me, you are already familiar with the testing concepts, and are looking for a book to learn about advanced testing concepts, theories, this book might be too little for you (or just read through the "There is more" sections of the recipies). But it is great for someone new to testing - though discussions with (and code reviews by) someone experienced in testing should accompany the reading.</p><br/><p>Despite the below criticisms, which are meant to be rather a companion to the book than an advice against it (i.e.: probably the only book I wouldn't find anything missing from and nothing to criticise about would be written for me, in real time, based on my immediate needs). The fact that the list is short shows how I found the rest of the book valuable, with great advices that go beyond the cookbook format (why you shouldn't use <code>fail()</code>, why there should be one assert per test, etc.). While I don't see eye to eye on each topic with the book, but just as the book is not written in a "my way or the highway" style, I will not get into minor differrences of opinion.</p><br/><h2>Format of the book</h2><br/><p>Each chapter explores a topic, with multiple specific recipes. Each recipe is relatively self contained, so if we are in a hurry and need to get to the solution of one specific problem without reading the whole book/chapter, it's possible. However, for those reading whole chapters, this results in a bit of repetition - I had to fight the urge to just gloss over the code I (thought) I had seen before. </p><br/><p>Each recepie follows the format of </p><br/><ul><br/><li>stating the problem</li><br/><li>showing code that solves it</li><br/><li>explaining how the code works</li><br/><li>and finally, providing warnings about pitfalls and problems in the code, and some further advice</li><br/></ul><br/><p>While this format is easy to follow, it has a few drawbacks.</p><br/><ul><br/><li>until I got used to this style, I often found myself cursing out loud like the <a href="http://www.osnews.com/story/19266/WTFs_m">code reviewers in this comic</a> while reading the code that will later be explained to be bad/antipattern. </li><br/><li>each recipe has a lot of additional testing insight, potentially unrelated to the tool being demonstrated - but one can miss these, thinking "oh, I know all about doctest, I'll just skip that chapter"</li><br/><li>for people in a hurry, just scanning the cookbook and copying (typing up) the code - there is nothing to indicate in the code that there is an antipattern there, only in the later paragrpahs - which you might not read when in a hurry. Just thinking about the examples where the unit tests have no asserts but only print statements gives me the shivers (and it's even used for illustration in the chapter about Continious Integration!).</li><br/></ul><br/><h2>What was missing from the book</h2><br/><ul><br/><li>About testing legacy code, I was missing two things: <ul><br/><li>a pointer to Michael Feather's classic book, <a href="http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052">Working Effectively with Legacy Code</a></li><br/><li>a warning about a mistake I have seen almost everyone (myself included) make when getting started with testing legacy code: don't write tests just because you can - only add cases for the area you are working on and only add enough to cover your current needs. This is hinted at, but I've found it's important to state it explicitly.</li><br/></ul><br/></li><br/><li>Notes about test maintainability <ul><br/><li>I strongly disagree with the approach of having one test class per physical class, and test methods directly excercising the class's method. I've found these can lead to maintainability problems down the road, so I prefer to introduce helper abstractions (e.g.: <code>assert_roman_numeral_conversion(expected_result, roman_numeral_string)</code> method) for most of my tests, and organize test methods by logical scenarios instead of mirroring code organizational units (on successful login, validating user input, etc.). These abstraction (indirections) makes it easier to update tests after an API change or refactoring. It might sound like an advanced topic, but I think it's a key concept for effective tests, and one that people should be exposed to early (just after they've made the mental jump from throwaway main methods with visual/human assertions to automated tests with automated assertions).</li><br/><li>Acceptance Testing - it is notoriously difficult for us programmers to <a href="http://blog.objectmentor.com/articles/2009/12/07/writing-maintainable-automated-acceptance-tests">write good acceptance tests</a> that are both maintainable and readable by the customers. I'm rather sure that in the example given in the book, the customers would not be interested in knowing which html tag contains the price in the output. </li><br/></ul><br/></li><br/></ul><br/><h2>Minor criticisms</h2><br/><ul><br/><li>there is an inconsistent level of detail and further pointers. E.g.: while <code>optparse</code> is explained in detail, <code>virtualenv</code> and <code>setuptools</code> are glossed over.</li><br/><li>In addition to the assertless test methods, the other thing that shocked me was the example in the doctest module that - to illustrate that the test works - introduced a bug in the test code. While the fact that test is code and thus can be buggy should be emphasized, but that wasn't the case here. This could leave the reader wondering why exactly we introduced the bug in the test code - aren't we testing the application?</li><br/><li>The book is careful not to fall into the trap of elitist speak that might alienate people, but saying that coupling and cohesiveness are subjective terms is just providing gunpowder to unwinnable arguments(*).</li><br/></ul><br/><h2>Interesting notes</h2><br/><ul><br/><li>This might be a cultural thing (I'm coming from .NET), but I've found it rather surprising that such an entry level book talks about test runners, and write custom test runners. It's useful knowledge, just something that I have not seen mentioned in so much detail in the Java/.NET world so early. Maybe it's got to do with IDEs being more widespread, where running a subset of the tests is easy.</li><br/></ul><br/><p>As said, the book lives up to the expectations, so if you would like to get a quick and practical introduction to testing in pytohn - both tools and concepts, I can recommend this one for you.</p><br/><hr/><br/><p>(*) Reminds me of a story from long ago. The team in question has decided to use bind variables for all SQL invocations (I've said it's been some time ago) to prevent SQL Injection. The one programmer wrote a stored procedure that concatenated the SQL command in its body... and argued that this is just a matter of style. At least the procedure was invoked from the application using bind parameters...</p>

          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2011/10/book-review-python-testing-cookbook-by.html">Book Review - Python Testing Cookbook by Greg L. Turnquist</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>Testing Strategy On Migration Projects</title>
      <link>http://blog.zsoldosp.eu/2011/09/testing-strategy-on-migration-projects.html</link>
      <pubDate>Mon, 19 Sep 2011 17:30:00 CEST</pubDate>
      <category><![CDATA[software]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[legacy code]]></category>
      <category><![CDATA[rewrite]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2011/09/testing-strategy-on-migration-projects.html</guid>
      <description>Testing Strategy On Migration Projects</description>
      <content:encoded><![CDATA[
          
<p>It's common for migration projects (a.k.a.: rewrite) to specify scope initially as "to behave the same way as the old system does". Thus the testing approach to <em>automatically compare the new system's results to the old system's</em> seems to be a perfect choice (of course, in addition to the data migration, calculations should be reconciled too - at least for the records that were calculated using the latest version of the old system).</p><br/><p>However, once the application goes live and the old one is decommissioned, we cannot rely on these tests anymore (there is no old system anymore), and <em>we have no regression suite to rely on for the future change requests/enhancements</em>.</p><br/><p>Just to avoid any misunderstanding: I don't advocate not having automated reconciliation checks (verifications), on the contrary, I think they are immensely valuable. We can write the best specifications/code, but still miss some details, which, luckily for us, do pop up in the real data. These automated checks give everyone on the project team the peace of mind they so need before go-live. </p><br/><p>The point I'm trying to make here is that <em>while these checks are essential, they are not enough for the long term health of the system</em>. These are a good starting point, but just as we do with the specifications, as we work on the new system, when we find and uncovered logic case (e.g.: as part of the calculation reconciliation), we need to add a test case to the new application's test suite to ensure proper regression coverage that we can rely on in the years to come. And adding this test case is easy - we can just copypaste (after making it anonymous of course) the input that caused the problem with the verification into the unit/functional tests, implement the missing functionality, and move on. But saving on these few seconds costs a lot later down the road.</p><br/><p>Unit/functional/integration/system tests are supposed to be self contained - we would like to create (a) clean database(s), which we put into a known state before the tests (some frameworks support this out of the box, e.g.: Django, but we can easily implement this ourselves).  Migration reconciliations, by their very nature, need to work on the live (snapshot) data. Also, as described earlier, these reconciliation tests are temporary artifacts, while the other tests supposed to be permanent (at least until the client decides to change the requirements). Separation of Concerns also applies to the test suite - running tests in the same suite with different assumptions (live db we shouldn't touch vs. empty test db we can read/write as we wish) is more than risky - keep them physically separated, both at runtime and in source control.</p><br/><p>Even if the delivered project could be summed up in that vague sentence (does what the old does), this summary is never true - few start rewrite projects just to get the exact same functionality. Usually these projects are sponsored because the old application became unmaintainable and the client is missing opportunities, because the software is not supporting, but hindering their goals. Without the self-contained test suite, our shiny new migrated application is going to become another one of these.</p>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2011/09/testing-strategy-on-migration-projects.html">Testing Strategy On Migration Projects</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
  </channel>
</rss>
