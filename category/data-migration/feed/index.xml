<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Do. Reflect. Learn. Repeat!</title>
    <link>http://blog.zsoldosp.eu</link>
    <description>Excercises in public learning</description>
    <pubDate>Sat, 05 Dec 2015 12:42:20 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>Data Migrations As Acceptance Tests</title>
      <link>http://blog.zsoldosp.eu/2011/11/data-migrations-as-acceptance-tests.html</link>
      <pubDate>Fri, 04 Nov 2011 09:23:00 CET</pubDate>
      <category><![CDATA[rewrite]]></category>
      <category><![CDATA[data migration]]></category>
      <category><![CDATA[testing]]></category>
      <category><![CDATA[tdd]]></category>
      <category><![CDATA[software]]></category>
      <category><![CDATA[approach]]></category>
      <category><![CDATA[legacy code]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2011/11/data-migrations-as-acceptance-tests.html</guid>
      <description>Data Migrations As Acceptance Tests</description>
      <content:encoded><![CDATA[
          
<p>While I have previously said that <a href="/2011/09/testing-strategy-on-migration-projects.html">on migration projects both verification and regression tests are important</a>, does it mean that the two should be separate? Like first, let's migrate the data, and then we'll rewrite the functionality, right? Or let's do it the other way around - we'll talk with the customer, incrementally figure out their requirements, deliver the software (with a proper regression test suite) that satisfies them, and then we migrate. Both approaches have problems:</p><br/><ul><br/><li>customers want to use the software with their current, real data - having only the data and no application to use it with is no value to them. Neither is having only an application with no data in it</li><br/><li>real data has lots of surprising scenarios that the domain expert might have forgotten to specify (see <em>caveats</em> though)</li><br/><li>requirements are not static, and new ones will be introduced during the development process, that inevitably will cause the new application's models to change, which means that <a href="http://blog.objectmentor.com/articles/2009/01/09/the-big-redesign-in-the-sky">the migration has a moving target it needs to migrate to</a>. </li><br/></ul><br/><h1>Doing them in parallel</h1><br/><p>If the data source is organized chronologically (<code>order by date</code> in the migration script), and organized in a format that resembles what the system's end users will enter into the system, then we can use the new application's outmost automatable entry point (Selenium, HTTP POST, a module's public API) to enter this data during the migration from the old system to the new.</p><br/><h2>Why</h2><br/><p>While a clear <em>disadvantage of this approach is speed of the migration</em> - it will be likely slower than an <code>INSERT INTO new_db.new_table select .... FROM old_db.old_table join ... where ....</code> statement, but in the case of non-trivial migrations it will likely compensate for the slowness, because:</p><br/><ul><br/><li>changes to the new system's code/data structure become a problem localized to the new application code - no headaches to update the migration scripts <em>in addition to the code</em></li><br/><li>when the client requests the demo deployment to be in sync with the old system, the code is ready (spare for the part to figure out which records have changed)</li><br/><li>the legacy data edge cases provides focus - no need to invent corner cases, for there will be enough in the data</li><br/><li>likely there will be releasable functionality sooner than with either of the above approaches</li><br/></ul><br/><h2>How</h2><br/><p>First, create the acceptance tests for the migration:</p><br/><ul><br/><li>Pick the data to be migrated</li><br/><li>find the view in the original system that displays this data to the users and find a way to extract the data from there</li><br/><li>define the equivalent view in the new system (it's about end to end, user visible features!)</li><br/><li>write the verification script that compares the above two (be sure to list the offending records in the failure message!)</li><br/><li>define the data entry point in the new system</li><br/><li>write the migration script - <em>extract</em> from the old system, <em>transform</em> if needed (only to match the entry points expectations of the format - no quality verification as in <a href="http://en.wikipedia.org/wiki/Extract%2C_transform%2C_load">classic ETL</a>!), then send it into the new system (using the above defined entry point)</li><br/></ul><br/><p>At this point both the new view, and the data entry points are empty. From here on, the <a href="http://pragprog.com/magazines/2011-11/testdriven-development">TDD</a> cycle becomes a nested loop</p><br/><ul><br/><li>run the migration script. See which record it failed for</li><br/><li>analyze the failing acceptance test, and find the missing features for it</li><br/><li><a href="http://gojko.net/FitNesse/book/">(A)TDD</a> the missing features</li><br/><li>run the migration script to restart the cycle</li><br/></ul><br/><h1>Caveats</h1><br/><p>While the existing data makes one focus on the real edge cases instead of the imagined one, beware - not everything has to (or can be) migrated - for instance, in a payment system, the system used to accept many currencies in the past, but now only <em>â‚¬</em>. IN this case, possibly the currency exchange handling logic could be dropped in the new system (and just to store the currency in a char field for the old ones); or in some other domains, maybe only the last ten years' data is needed. However, <em>this should be a business decision</em>, not a decision for a developer!</p><br/><p><em>Source Data Quality</em> is often a problem, one that will likely cause issues. If data needs to be fixed (as above, ask the stakeholders!), it should <em>stay out from your application's code</em>, and be in the <em>Transform</em> part of the migration script.</p>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2011/11/data-migrations-as-acceptance-tests.html">Data Migrations As Acceptance Tests</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
  </channel>
</rss>
