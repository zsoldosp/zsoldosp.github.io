<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>Do. Reflect. Learn. Repeat!</title>
    <link>http://blog.zsoldosp.eu</link>
    <description>Excercises in public learning</description>
    <pubDate>Fri, 01 Dec 2023 08:41:16 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>warnings.warn - some DeprecationWarning gotchas</title>
      <link>http://blog.zsoldosp.eu/2016/02/01/warnings-warn-some-deprecationwarning-gotchas/</link>
      <pubDate>Mon, 01 Feb 2016 11:17:00 CET</pubDate>
      <category><![CDATA[python]]></category>
      <category><![CDATA[warnings]]></category>
      <category><![CDATA[deprecation]]></category>
      <category><![CDATA[executable documentation]]></category>
      <category><![CDATA[software]]></category>
      <category><![CDATA[gotcha]]></category>
      <category><![CDATA[til]]></category>
      <guid isPermaLink="false">bQ24ZuZG1n9rOMCSVN81UBv0wpU=</guid>
      <description>warnings.warn - some DeprecationWarning gotchas</description>
      <content:encoded><![CDATA[
          <h2 id="deprecationwarnings"><code>DeprecationWarning</code>s</h2>
<p>It's a good practice to gradually deprecate one's library's API, so that 
users get advance warning of coming changes. The built in way to
do so is Python's <a href="https://docs.python.org/3.5/library/warnings.html"><code>warnings</code> module</a></p>
<pre><code>import warnings

if __name__ == '__main__':
    warnings.warn('deprecation', DeprecationWarning)
</code></pre>
<h2 id="by-default-they-are-not-reported">By default, they are not reported!</h2>
<p>However, if I run this code, there is no output.</p>
<pre><code>$ python3.5 demo.py
$ echo $?
0
</code></pre>
<p>The <a href="https://docs.python.org/3.5/library/warnings.html#default-warning-filters">documentation on default warning filters</a> explains: </p>
<blockquote>
<p>By default, Python installs several warning filters, which can be overridden by the command-line 
options passed to <code>-W</code> and calls to <code>filterwarnings()</code>.</p>
<ul>
<li><code>DeprecationWarning</code> and <code>PendingDeprecationWarning</code>, and <code>ImportWarning</code> are ignored.</li>
<li><code>BytesWarning</code> is ignored unless the <code>-b</code> option is given once or twice; in this case
   this warning is either printed (<code>-b</code>) or turned into an exception (<code>-bb</code>).</li>
<li><code>ResourceWarning</code> is ignored unless Python was built in debug mode.
</li>
</ul>
</blockquote>
<h2 id="forcing-defaults-from-the-command-line-makes-them-reported">Forcing defaults from the command line makes them reported</h2>
<p>However, if we force the <a href="https://docs.python.org/3.5/using/cmdline.html#cmdoption-W"><em>default</em> warning behavior from the command line</a>,
we get the warnings - even though theoretically we only specified <em>how often</em> the warnings
should be reported, not <em>which</em> warnings to be reported!</p>
<pre><code>$ python3.5 -W d demo.py
demo.py:4: DeprecationWarning: deprecation
  warnings.warn('warning', DeprecationWarning)
$ echo $?
0
</code></pre>
<p>Before reading the docs, I suspected the operating system maintainers didn't want to 'spam'
the end users of their systems with python library warnings while going about their daily 
tasks, but apparently this is built into python itself.</p>
<h2 id="so-how-should-i-deprecate-things">So how should I deprecate things?</h2>
<p>I'm a big fan of <a href="/2010/08/executable-documentation.html">executable documentation</a>, but this might be one of those cases
where good old fashioned documentation might be more effective, as we can't expect users of
our library to run with warnings enabled.</p>
<p>I would still leave in these deprecations for the project's developers as well as for the
pedant users of the library.</p>
<h2 id="checking-against-deprecations-of-our-dependencies">Checking against deprecations of our dependencies</h2>
<p>That's easier, as we own that code. I would run my builds and tests with <code>-W d</code> at the very
least, but I would like to try to run with <code>-W error</code>. Except that I don't want to fail the
build if one of my dependencies is using deprecated apis, so probably I would just have a
custom <code>main.py</code> where I would explicitly set and reset my warning filters. E.g.: updating
the above demo code would give me the following:</p>
<pre><code>import warnings
import os

if os.environ.get('TEST', '0') == '1':
    warnings.filterwarnings(module='.*', action='ignore')
    warnings.filterwarnings(module=__name__, action='error')

if __name__ == '__main__':
    warnings.warn('deprecation', DeprecationWarning)
</code></pre>
<p>&nbsp;</p>
<pre><code>$ TEST=1 python3.5 demo.py
Traceback (most recent call last):
  File "demo.py", line 8, in &lt;module&gt;
    warnings.warn('deprecation', DeprecationWarning)
DeprecationWarning: deprecation
$ echo $?
1
</code></pre>
<p>I yet have to test how feasible it is when our library supports multiple versions of a 
dependent library, e.g.: <a href="https://www.djangoproject.com/">Django</a>, but my gut feeling is that it should be doable</p>
<h3 id="beware-of-the-ordering-of-warning-filters">Beware of the ordering of warning filters</h3>
<p>If in the above example we got the order reversed, then our own <code>DeprecationWarning</code>s would
be ignored too!</p>
<pre><code>if os.environ.get('TEST', '0') == '1':
    warnings.filterwarnings(module=__name__, action='error')
    warnings.filterwarnings(module='.*', action='ignore')
</code></pre>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2016/02/01/warnings-warn-some-deprecationwarning-gotchas/">warnings.warn - some DeprecationWarning gotchas</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>Executable bug tracker</title>
      <link>http://blog.zsoldosp.eu/2010/08/executable-bug-tracker.html</link>
      <pubDate>Mon, 30 Aug 2010 21:18:00 CEST</pubDate>
      <category><![CDATA[bug tracking]]></category>
      <category><![CDATA[software]]></category>
      <category><![CDATA[automated testing]]></category>
      <category><![CDATA[executable documentation]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2010/08/executable-bug-tracker.html</guid>
      <description>Executable bug tracker</description>
      <content:encoded><![CDATA[
          
<span class="Apple-style-span" style="font-size: small;">Disclaimer: I have (yet) no practical experience with the concept I describe below, it is a </span><i><span class="Apple-style-span" style="font-size: small;">"thinking out loud"</span></i><span class="Apple-style-span" style="font-size: small;"> kind of post. The context is a team working on a product in the maintenance/legacy phase of its life-cycle, with developers who are already comfortable with automated testing.</span><sup><span class="Apple-style-span" style="font-size: x-small;">1</span></sup><div><br/><div>It will be about the small, nice to have priority bugs/known issues. The ones that never get formally prioritized in any of the releases, because there are always more important features issues. The ones that you record in your issue tracker, to keep your conscience at peace; and which will be closed as "won't fix" at the end.</div><div><br/></div><div>Some advocate<sup><span class="Apple-style-span" style="font-size: x-small;">2</span></sup> that you should just save yourself the trouble of maintaining these bugs at all, and just don't bother recording them until clients/managements push for it. </div><div><br/></div><div>To clarify: I'm not against not prioritizing issues by the clients. However, I would love to find a way to give a chance for these issues to be fixed, without compromising delivery of business features.</div><div><br/></div><div>One of the contributing factors why these issues don't get fixed (IMHO, of course :)) is that it takes a lot of effort to actually find a bug to fix when you have some slack time. You have to search through your tracker for open bugs, scan them to pick one, build up the context to actually begin to work on it (aka.: getting into the zone), etc. All this makes it too much of a hassle when all you have is a spare few minutes, and would be happy to fix an issue nearby the current module you are working on otherwise, but not with this extra burden added.</div><div><br/></div></div><div>A possible solution is to have a collection of automated tests reproducing the bugs, with asserts that fail on the current codebase. These tests live separate from  the main test suite (extra jar/DLL, categories, namespace, etc.), but live together in the IDE with the app (to aid refactoring). There could even be a custom test runner or an additional step in the build process to notify you if any of these bugs are fixed - you might even fix one accidentally.</div><div><br/></div><div>With such a setup we can rely on static code analysis to find bugs in the area of the code we are about to start working on/just finished with; thus lowering the cost for one to begin working on a bug. Even if one won't fix it straight away, the test could be simply improved upon (remember <a href="http://www.informit.com/articles/article.aspx?p=1235624&amp;seqNum=6">the boyscout rule</a>?).</div><div><br/></div><div>The one concern I have is with the recording phase of this process - many a time the most costly part of fixing a bug is actually finding a way to reproduce it :) However, if the original "bug report" is the programmatic equivalent of "open this form, enter these values, then right click and observe the application crash", it might not add a noticeable overhead (especially in comparison to filing a bug report in the issue tracker).</div><div><br/></div><div><hr/><span class="Apple-style-span" style="font-size: x-small;">1. or open source projects</span></div><div><span class="Apple-style-span" style="font-size: x-small;">2. see disclaimer - it might actually make sense if working on a well kept codebase, with frequent releases.</span></div>
          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2010/08/executable-bug-tracker.html">Executable bug tracker</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
    <item>
      <title>Executable documentation</title>
      <link>http://blog.zsoldosp.eu/2010/08/executable-documentation.html</link>
      <pubDate>Thu, 19 Aug 2010 19:56:00 CEST</pubDate>
      <category><![CDATA[automation]]></category>
      <category><![CDATA[software]]></category>
      <category><![CDATA[executable documentation]]></category>
      <guid isPermaLink="false">http://blog.zsoldosp.eu/2010/08/executable-documentation.html</guid>
      <description>Executable documentation</description>
      <content:encoded><![CDATA[
          
<span><div>It's good to see <a href="http://continuousdelivery.com/">build and release automation</a> becoming <a href="http://somic.org/2010/08/17/the-biggest-challenge-for-infrastructure-as-code/">more</a> and <a href="http://www.markhneedham.com/blog/2010/08/18/database-configuration-just-like-any-other-change/">more </a> common, but I'm curious to see whether this wave of automation will stop at just releasing or flow over to other areas of software development, and change the attitude in general.</div><div><br/></div><div>Though  automated testing and continuous integration took some time to spread - despite the fact that software developers (who spend their days automating mundane tasks so clients can focus on adding value, and thus should have been easily convinced)  have been (and some are still) opposed to the idea of automating the mundane tasks that <i>they</i> perform; I'm hoping that one of my pet peeves - stale documentation - will become more and more extinct as automation becomes more mainstream.</div><div><br/></div><div>Below are just some document types that could be made live and executable:</div><div><ul><li><b>Specifications</b>. I'm not the first to suggest this, acceptance testing, tools, and books have been around, but haven't caught on yet. I've been introduced to this concept by <a href="http://gojko.net/">Gojko Adzic</a>, and I can recommend his <a href="http://skillsmatter.com/expert/design-architecture/gojko-adzic">past talks/videos</a> or books for getting started on this topic.</li><li>New developer <b>getting started instructions</b>. In addition to local machine setup (though the approach <a href="http://twitter.com/sipostamas">Tamas Sipos</a> described of using virtual machines per project is even better than scripting it), this usually includes gaining access to all sorts of different file shares, web services, machines, databases, mapping them to proper local names, and so forth. This is usually presented in the form of list, where you actually copy-paste it into the command line. There is no reason this couldn't be scripted. <i>Mirroring</i> access from an existing developer is sometimes easier than keeping the setup scripts up to date.</li><li><b>Revoking access</b> from departing developers. This might be more applicable to bigger enterprise environments, but it is just as important as setting up a new developer. Script it.</li><li>Installation instructions, and <b>fixlogs/workarounds</b> for 3rd party applications (or even your own applications). These are the ones that warn you to only ever run this script as a given user. Or from a particular machine. And to execute the following commands, containing a loops and decision branches, written in plain text. And to make SQL calls, send xml/json messages, where you just need to substitue &lt;this&gt; with the current value, etc.  Script them, and make reduce the document to a single instruction - execute myFix.sh with the following two parameters.</li><li>Code review guidelines, <b>coding standards</b>. Naming conventions, indentations, method length/complexity, all sorts of other static code analysis (the domain shouldn't call the UI code directly! We shouldn't have commented out code! There should be no Windows Forms controls with Visible = false never ever changed elsewhere to true in the class! etc.) should not be done by hand if  can be automated - and there are quite a number of mature tools out there, all  extensible, such as <a href="http://stylecop.codeplex.com/">StyleCop</a>, <a href="http://msdn.microsoft.com/en-us/library/bb429476(v=VS.80).aspx">FxCop</a>, <a href="http://checkstyle.sourceforge.net/">Checkstyle</a>,  <a href="http://findbugs.sourceforge.net/">FindBugs</a>, <a href="http://www.xdepend.com/">xDepend</a>. Focus code reviews on the more important things. </li><li><b>Data flow</b> diagrams. For the live, production system, you are better off generating this dependency graph from the scheduling tool you use, which makes it surely represent production, as opposed to the manually maintained Visio diagram or similar.</li></ul><div>Hope it was inspiring :) Do you know more document types I have missed?</div></div></span>

          <hr />
          The post <a hef="http://blog.zsoldosp.eu/2010/08/executable-documentation.html">Executable documentation</a> first appeared on <a href="http://blog.zsoldosp.eu">http://blog.zsoldosp.eu</a>.
        ]]></content:encoded>
    </item>
  </channel>
</rss>
